{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VectorizeAssignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05bd9c87eb974f67a078ecd909baee91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_460fb81582184330a749e0d954cd1a3b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1725c98a23dc42dc8dcfcf746a04ec9b",
              "IPY_MODEL_880151db24794901b4989c903f2b9799"
            ]
          }
        },
        "460fb81582184330a749e0d954cd1a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1725c98a23dc42dc8dcfcf746a04ec9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_4bce9a6bc3d141039ca6230b65e2c16d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cbef3ab3ec742c1a62c6fdb954ca9de"
          }
        },
        "880151db24794901b4989c903f2b9799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a65a06945c8e4a28af0066c4fcabce52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e9b5daaa71b4fb48834e2b220ccefb2"
          }
        },
        "4bce9a6bc3d141039ca6230b65e2c16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cbef3ab3ec742c1a62c6fdb954ca9de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a65a06945c8e4a28af0066c4fcabce52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e9b5daaa71b4fb48834e2b220ccefb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5f2917e223448f0b376e9167c9de07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_66b0ab3949404e9e8b42786a02d5a144",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bb8d4df2a27e4acea430b2e570d7f0fc",
              "IPY_MODEL_2655a6e7cd1c4ae0aa40e256454102eb"
            ]
          }
        },
        "66b0ab3949404e9e8b42786a02d5a144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb8d4df2a27e4acea430b2e570d7f0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_c9db0de8273d47f385f1341c4446652a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.06MB of 0.06MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d457176854249e6866e1d58e2f5d8e5"
          }
        },
        "2655a6e7cd1c4ae0aa40e256454102eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_daafb11950d84a7bac61cadd4e7c6619",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8390919e84054f6ca73247035857e703"
          }
        },
        "c9db0de8273d47f385f1341c4446652a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d457176854249e6866e1d58e2f5d8e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "daafb11950d84a7bac61cadd4e7c6619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8390919e84054f6ca73247035857e703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anish-sk/CS6910_Assignment1/blob/master/src/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DMWBsOgIyM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a32f436-ef65-4ad7-c838-f984041748ae"
      },
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login 6746f968d95eb71e281d6c7772a0469574430408"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: wandb in /usr/local/lib/python3.7/dist-packages (0.10.22)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.0.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
            "Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd2ZVTXmJfT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a88bcd4-8591-443e-c92e-c80882455a05"
      },
      "source": [
        "# Init wandb\n",
        "import wandb\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "# Loading the fashion-MNIST dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "# Setting seed value\n",
        "np.random.seed(1)\n",
        "\n",
        "# Load dataset (train data and test data)\n",
        "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n",
        "\n",
        "# Summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtNK58VvJrZO"
      },
      "source": [
        "\n",
        "# Number of classes in the Fashion-MNIST dataset\n",
        "N_CLASSES = np.unique(trainy).shape[0]    # 10 as known from the keras documentation\n",
        "\n",
        "# Captions/Labels for the output classes present in Fashion-MNIST dataset\n",
        "IMG_LABELS = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "\n",
        "def getSampleImages(nClass, imgLabels, X, y, nSamples):\n",
        "  '''\n",
        "  The function takes few samples of each class from the dataset provided and passes it to the WANDB for it log the images\n",
        "\n",
        "  Arguments :\n",
        "    nClass -- Number of output classes in the dataset\n",
        "    imgLabels -- List of labels for the output classes (numbered from 0 to nClass - 1)\n",
        "    X -- The input data containing images in the form of matrices\n",
        "    y -- The output data containing the class to which an input belongs\n",
        "    nSamples -- Number of samples of each class to be taken. If that many samples not present in dataset, maximum number of samples present (from that class) will be taken\n",
        "\n",
        "  Returns :\n",
        "    -- None --\n",
        "  '''\n",
        "\n",
        "  # Initialise empty list to store the input data sampled from each class\n",
        "  sampleImgsX = [[] for _ in range(nClass)]\n",
        "\n",
        "  # Take sample image(s) from each class\n",
        "  for i in range(y.shape[0]):\n",
        "    if len(sampleImgsX[y[i]]) < nSamples :\n",
        "      sampleImgsX[y[i]].append(X[i])\n",
        "\n",
        "\n",
        "  # Getting a list of sample images of each class to be saved to wandb\n",
        "  sampleImgsList = []\n",
        "  for i in range(nClass):\n",
        "    for j in range(nSamples):\n",
        "      sampleImgsList.append(wandb.Image(sampleImgsX[i][j], caption = imgLabels[i]))\n",
        "\n",
        "  np.random.shuffle(sampleImgsList)\n",
        "  wandb.log({\"example\" : sampleImgsList})\n",
        "\n",
        "\n",
        "# Question 1 -- Showing 3 sample images from training set of downloaded Fashion-MNIST dataset in WANDB\n",
        "# ---------------- Uncomment the below code to run -----------------\n",
        "\n",
        "# run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "# getSampleImages(N_CLASSES, IMG_LABELS, trainX, trainy, 1)\n",
        "# run.finish()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbufY1DHNQdm"
      },
      "source": [
        "def relu(X):\n",
        "  # Calculates the Rectified Linear Unit (ReLU) function\n",
        "  return np.maximum(X,0)\n",
        "\n",
        "def sigmoid(X):\n",
        "  # Calculates the sigmoid function\n",
        "  return np.exp(-np.logaddexp(0, -X))\n",
        "\n",
        "def softmax(X):\n",
        "  # Calculates the softmax function\n",
        "  e_X = np.exp(X - np.max(X, axis = 0))\n",
        "  return e_X / e_X.sum(axis = 0)\n",
        "\n",
        "def tanh(X):\n",
        "  return np.tanh(X)\n",
        "\n",
        "def linear(W, X, b):\n",
        "  # Calculates the linear function\n",
        "  return W @ X + b\n",
        "\n",
        "def grad_relu(X):\n",
        "  # Calculates the gradient of Rectified Linear Unit (ReLU) function\n",
        "  return X > 0\n",
        "\n",
        "def grad_sigmoid(X):\n",
        "  # Calculates the gradient of sigmoid function\n",
        "  return sigmoid(X) * (1 - sigmoid(X))\n",
        "\n",
        "def grad_tanh(X):\n",
        "  # Calculates the gradient of tanh function\n",
        "  return 1 - np.tanh(X)**2\n",
        "\n",
        "def Softmax_CrossEntropy_grad(Y_pred, Y):\n",
        "  # Calculates the gradient of the output layer with softmax activation and cross entropy loss\n",
        "  # layer -- The dictionary for the output layer contianing info about it\n",
        "  # y -- True output\n",
        "  return -(Y - Y_pred)\n",
        "\n",
        "def Softmax_SquaredError_grad(Y_pred, Y):\n",
        "  return ((Y_pred - Y) - ((Y_pred - Y) * Y_pred).sum(axis = 0)) * Y_pred "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX_08I3AJaiF"
      },
      "source": [
        "def random_initialisation(shape):\n",
        "  # Initialising a random matrix with given dimensions (shape) as tuple\n",
        "  np.random.seed(0)\n",
        "  return np.random.randn(*shape)*0.1\n",
        "\n",
        "def xavier_initialisation(shape):\n",
        "  # Initialising a matrix by xavier initialisation with given dimensions (shape) as tuple\n",
        "  np.random.seed(0)\n",
        "  bound = (6/(shape[0]+shape[1]))**(0.5)\n",
        "  return bound*(2*np.random.rand(*shape)-1)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3rWXP7YMDOS"
      },
      "source": [
        "def initialize_network(n_L, preActFns_L, actFns_L, gradActFns_L, gradOutputFn, weight_initialisation):\n",
        "  '''\n",
        "  The function initializes the neural network and the appropriate parameters\n",
        "  \n",
        "  Arguments :\n",
        "    n_L -- an array whose ith element represents the number of neurons in the ith layer (0 - Input Layer, last element - Output Layer)\n",
        "    preActFns_L -- an array who ith element is the Pre Activation function of the (i+1)th layer of the neural network\n",
        "    actFns_L -- an array who ith element is the Activation function of the (i+1)th layer of the neural network\n",
        "    gradActFns_L -- an array who ith element is the gradient of the Activation function of the (i+1)th layer of the neural network\n",
        "    gradOutputFn -- Function to calculate gradients wrt a_L (output layer) in back-propagation\n",
        "    weight_initialisation -- Function to initialise weights of the layers\n",
        "  \n",
        "  Returns :\n",
        "    network -- the initialized network as an array of dictionaries for the hidden and output layers of the neural network\n",
        "  '''\n",
        "\n",
        "  L = len(n_L)-1\n",
        "\n",
        "  assert(L >= 1)\n",
        "  assert(len(preActFns_L) == L)\n",
        "  assert(len(actFns_L) == L)\n",
        "\n",
        "  network = list()\n",
        "  for i in range(1,L+1):\n",
        "    # Dictionary for each layer representing it's constituents\n",
        "    layer = {'weights':weight_initialisation((n_L[i],n_L[i-1])),  # Weight matrix for (i-1)th to ith layer transition\n",
        "             'biases':np.zeros((n_L[i],1)),                       # Bias vector for (i-1)th to ith layer transition\n",
        "             'pre_activation_fn':preActFns_L[i-1],                # Pre-activation function for neurons of the ith layer\n",
        "             'activation_fn':actFns_L[i-1],                       # Activation function for neurons of the ith layer             \n",
        "             'no_neurons':n_L[i],                                 # Number of neurons in ith layer\n",
        "             'cache': []                                          # Array of cached pre-activation and activation output for each layer to be used in back-propagation (will be filled in forward-propagation)\n",
        "            }\n",
        "    network.append(layer)\t\n",
        "    if i < L:\n",
        "      network[-1]['grad_activation_fn'] = gradActFns_L[i-1]       # Function calculating Gradient of the Activation function for the ith (hidden) layer\n",
        "  \n",
        "  network[-1]['grad_output_fn'] = gradOutputFn                    # Function calculating Gradient of the Output layer (Gradient of Loss function wrt a_L)\n",
        "\n",
        "  return network\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sDSj4aTPeTw"
      },
      "source": [
        "def pre_activation(H_prev, W, b, pre_activation_fn):\n",
        "  # Calculates the pre-activation output and caches the required values. Returns the output and cache.\n",
        "\n",
        "  A = pre_activation_fn(W, H_prev, b)\n",
        "  \n",
        "  assert(A.shape[0] == W.shape[0])\n",
        "  pre_act_cache = H_prev                    # Caching the pre-activation ouptut to be used in backpropagation\n",
        "\n",
        "  return A, pre_act_cache\n",
        "\n",
        "def feedforward_neuron(H_prev, W, b, activation_fn, pre_activation_fn):\n",
        "  # Calculates the activation output (using the pre-activation function above) and caches the required values. Returns the output and cache.\n",
        "\n",
        "  A, pre_activation_cache = pre_activation(H_prev, W, b, pre_activation_fn)\n",
        "  H = activation_fn(A)\n",
        "  \n",
        "  assert (H.shape[0] == W.shape[0])\n",
        "  cache = (pre_activation_cache, A)         # Caching the pre-activation and activation output to use it in back-propagation\n",
        "\n",
        "  return H, cache"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVFXPTolPf5v"
      },
      "source": [
        "def forward_propagation(network, X):\n",
        "    \"\"\"\n",
        "    Implement forward propagation for the given neural network\n",
        "    \n",
        "    Arguments :\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      X -- Input data from the training set as a matrix with ith column representing ith input training data\n",
        "    \n",
        "    Returns :\n",
        "      Output from the neural network as a matrix with ith column representing output of ith input data\n",
        "    \"\"\"\n",
        "\n",
        "    H = X                         # Initialising H to input\n",
        "    L = len(network)              # Number of (hidden + output) layers in the neural network\n",
        "\n",
        "    for l in range(0, L):\n",
        "        H_prev = H \n",
        "        H, cache = feedforward_neuron(H_prev, network[l]['weights'], network[l]['biases'], network[l]['activation_fn'], network[l]['pre_activation_fn'])\n",
        "        network[l]['cache'] = cache\n",
        "    \n",
        "    assert(H.shape[0] == (network[L-1]['no_neurons']))\n",
        "        \n",
        "    return H\n",
        "\n",
        "# HL = forward_propagation(trainX_reshaped, network)          # HL -- output from the neural network\n",
        "# print(HL)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCQvQGxcaCTC"
      },
      "source": [
        " def back_propagation(network, Y, Y_pred, weight_decay, grad_reglr_fn):\n",
        "  \"\"\"\n",
        "    Implement backward propagation for the given neural network\n",
        "    \n",
        "    Arguments :\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      Y -- True output matrix with ith column representing true output of ith input data\n",
        "      Y_pred -- Output of neural network as a matrix in the same form as Y\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "    \n",
        "    Returns :\n",
        "      H -- Output from the neural network\n",
        "  \"\"\"\n",
        "\n",
        "  L = len(network)\n",
        "  assert(Y.shape[1] == Y_pred.shape[1])\n",
        "  M = Y.shape[1]\n",
        "\n",
        "  # Gradients wrt output layer (a_L)\n",
        "  grad_a_k_L = network[L-1]['grad_output_fn'](Y_pred, Y)\n",
        "\n",
        "  # Initialising gradients to be calculated in the loop below\n",
        "  grad_w_L = [np.zeros(2)] * L\n",
        "  grad_b_L = [np.zeros(2)] * L\n",
        "  grad_h_prev_L, grad_a_prev_L = 0, 0\n",
        "\n",
        "  for k in range(L-1,-1,-1):\n",
        "    # Gradients wrt Weights (W_k)\n",
        "    grad_w_L[k] = (grad_a_k_L @ network[k]['cache'][0].T / M) + weight_decay * grad_reglr_fn(network[k]['weights'])\n",
        "\n",
        "    # Gradients wrt Biases (b_k)\n",
        "    grad_b_L[k] = np.mean(grad_a_k_L, axis=1)\n",
        "    grad_b_L[k] = grad_b_L[k].reshape((grad_b_L[k].shape[0], 1))\n",
        "    \n",
        "    # Gradients wrt hidden layer\n",
        "    # Gradients wrt h_(k-1)\n",
        "    grad_h_prev_L = network[k]['weights'].T @ grad_a_k_L\n",
        "\n",
        "    # Gradients wrt a_(k-1)\n",
        "    if(k > 0):\n",
        "      grad_act_fn_prev = network[k-1]['grad_activation_fn'](network[k-1]['cache'][1])\n",
        "      grad_a_prev_L = grad_h_prev_L * grad_act_fn_prev\n",
        "\n",
        "    grad_a_k_L = grad_a_prev_L\n",
        "\n",
        "  return grad_w_L, grad_b_L"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knKqQELwYpeb"
      },
      "source": [
        "def L2_regularisation(network):\n",
        "  # Function that returns L2 regularisation loss for the given network\n",
        "  L = len(network)\n",
        "  ans = 0\n",
        "  for k in range(L):\n",
        "    ans += np.sum(network[k]['weights'] ** 2)\n",
        "  \n",
        "  return ans\n",
        "\n",
        "def L1_regularisation(network):\n",
        "  # Function that returns L1 regularisation loss for the given network\n",
        "  L = len(network)\n",
        "  ans = 0\n",
        "  for k in range(L):\n",
        "    ans += np.sum(np.absolute(network[k]['weights']))\n",
        "  \n",
        "  return ans\n",
        "\n",
        "def grad_L2_regularisation(W):\n",
        "  # Function that returns L2 regularisation gradient for the given Weight matrix / tensor\n",
        "  return 2 * W\n",
        "\n",
        "def grad_L1_regularisation(W):\n",
        "  # Function that returns L1 regularisation gradient for the given Weight matrix / tensor\n",
        "  return np.sign(W)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyD4oPSIL19s"
      },
      "source": [
        "def CrossEntropy_loss(Y_pred, Y_true):\n",
        "  # Function that returns cross entropy loss\n",
        "  assert(Y_pred.shape[1] == Y_true.shape[1])\n",
        "  M = Y_pred.shape[1]\n",
        "  return -(Y_true * np.log(Y_pred)).sum() / M\n",
        "\n",
        "def SquaredError(Y_pred, Y_true):\n",
        "  # Function that returns mean squared loss\n",
        "  assert(Y_pred.shape[1] == Y_true.shape[1])\n",
        "  M = Y_pred.shape[1]\n",
        "  return ((Y_true - Y_pred) ** 2).sum() / (2.0 * M)\n",
        "\n",
        "def overall_loss(network, Y_pred, Y_true, loss_fn = CrossEntropy_loss, weight_decay = 0, regularisation_fn = L2_regularisation):\n",
        "  # Function that returns overall loss (Output layer cost function + Regularisation) for the network\n",
        "  return loss_fn(Y_pred, Y_true) + weight_decay * regularisation_fn(network)\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6abLgZ7KRtM"
      },
      "source": [
        "  def calc_accuracy_loss(network, X, Y, loss_fn = CrossEntropy_loss, weight_decay = 0, regularisation_fn = L2_regularisation):\n",
        "    # Function that returns the accuracy and loss for a given network\n",
        "    Y_pred = forward_propagation(network, X)\n",
        "    loss = overall_loss(network, Y_pred, Y, loss_fn, weight_decay, regularisation_fn)\n",
        "    assert(X.shape[1] == Y.shape[1])\n",
        "    M = X.shape[1]\n",
        "    accuracy = np.sum(np.argmax(Y_pred, axis = 0) == np.argmax(Y, axis = 0)) / M\n",
        "    return accuracy, loss"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXZpq0rM0Vvf"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def sgd_gradient_descent(X, Y, network, batch_size, eta, max_epochs, loss_fn = CrossEntropy_loss, weight_decay = 0, \n",
        "                         regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using Vanilla/Batch Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input training data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True training output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (training accuracy, average training loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (validation accuracy, average validation loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "\n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "  dw, db = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "  \n",
        "  for epoch in tqdm(range(max_epochs)):        \n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "      batch += 1\n",
        "      Y_true = Y[:,i:i+batch_size]\n",
        "      Y_pred = forward_propagation(network, X[:,i:i+batch_size])\n",
        "      batch_curr_loss = overall_loss(network, Y_pred, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "      dw, db = back_propagation(network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "      batch_loss_values.append(batch_curr_loss)\n",
        "      wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "      for k in range(L):\n",
        "        network[k]['weights'] -= eta * dw[k]\n",
        "        network[k]['biases'] -= eta * db[k]\n",
        "    \n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "\n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "  \n",
        "  return batch_loss_values, train_stats, valid_stats\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwQkfH0-oz4A"
      },
      "source": [
        "def momentum_gradient_descent(X, Y, network, batch_size, eta, max_epochs, loss_fn = CrossEntropy_loss, beta = 0.9, weight_decay = 0, \n",
        "                              regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using Momentum Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      beta -- Hyperparameter to tune dependency of gradient on history (standard value 0.9 used)\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (training accuracy, average training loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (validation accuracy, average validation loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "\n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "  dw, db, m_w, m_b = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                     [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "\n",
        "  for epoch in tqdm(range(max_epochs)):  \n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "      batch += 1\n",
        "      Y_true = Y[:,i:i+batch_size]\n",
        "      Y_pred = forward_propagation(network, X[:,i:i+batch_size])\n",
        "      batch_curr_loss = overall_loss(network, Y_pred, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "      dw, db = back_propagation(network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "      batch_loss_values.append(batch_curr_loss)\n",
        "      wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "      for k in range(L):\n",
        "        m_w[k] = m_w[k] * beta + dw[k] * eta\n",
        "        m_b[k] = m_b[k] * beta + db[k] * eta\n",
        "        network[k]['weights'] -= m_w[k]\n",
        "        network[k]['biases'] -= m_b[k]\n",
        "  \n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "\n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "  \n",
        "  return batch_loss_values, train_stats, valid_stats\n",
        "\n",
        "\n",
        "def nesterov_gradient_descent(X, Y, network, batch_size, eta, max_epochs, loss_fn = CrossEntropy_loss, beta = 0.9, weight_decay = 0, \n",
        "                              regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using Nesterov Accelerated Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      beta -- Hyperparameter to tune dependency of gradient on history (standard value 0.9 used)\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (training accuracy, average training loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (validation accuracy, average validation loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "  dw, db, m_w, m_b = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                     [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "\n",
        "  lookahead_network = network[:]\n",
        "\n",
        "  for epoch in tqdm(range(max_epochs)):\n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "      batch += 1\n",
        "      Y_true = Y[:,i:i+batch_size]\n",
        "      Y_pred_org = forward_propagation(network, X[:,i:i+batch_size])\n",
        "      batch_curr_loss = overall_loss(network, Y_pred_org, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "      Y_pred = forward_propagation(lookahead_network, X[:,i:i+batch_size])\n",
        "      dw, db = back_propagation(lookahead_network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "      batch_loss_values.append(batch_curr_loss)\n",
        "      wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "      for k in range(L):\n",
        "        m_w[k] = m_w[k] * beta + dw[k] * eta\n",
        "        m_b[k] = m_b[k] * beta + db[k] * eta\n",
        "        network[k]['weights'] -= m_w[k]\n",
        "        network[k]['biases'] -= m_b[k] \n",
        "        lookahead_network[k]['weights'] -= (eta * dw[k] + beta * m_w[k])\n",
        "        lookahead_network[k]['biases'] -= (eta * db[k] + beta * m_b[k])\n",
        "\n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "    \n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "\n",
        "  return batch_loss_values, train_stats, valid_stats\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K2eWRLqPUiw"
      },
      "source": [
        "def rmsprop_gradient_descent(X, Y, network, batch_size, eta, max_epochs, loss_fn = CrossEntropy_loss, eps = 1e-8, beta = 0.9,\n",
        "                             weight_decay = 0, regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, \n",
        "                             validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using RMSProp Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      eps -- Epsilon hyperparameter\n",
        "      beta -- Hyperparameter acting as decaying weight for learning rate update (standard value 0.9 used)\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (training accuracy, average training loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (validation accuracy, average validation loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "    \n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "\n",
        "  dw, db, v_w, v_b = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                     [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "\n",
        "  for epoch in tqdm(range(max_epochs)):  \n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "        batch += 1\n",
        "        Y_true = Y[:,i:i+batch_size]\n",
        "        Y_pred = forward_propagation(network, X[:,i:i+batch_size])\n",
        "        batch_curr_loss = overall_loss(network, Y_pred, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "        dw, db = back_propagation(network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "        batch_loss_values.append(batch_curr_loss)\n",
        "        wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "        for k in range(L):\n",
        "          v_w[k] = v_w[k] * beta + (1-beta) * dw[k]**2\n",
        "          v_b[k] = v_b[k] * beta + (1-beta) * db[k]**2\n",
        "          network[k]['weights'] -= (eta / np.sqrt(v_w[k] + eps)) * dw[k]\n",
        "          network[k]['biases'] -= (eta / np.sqrt(v_b[k] + eps)) * db[k]\n",
        "    \n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "\n",
        "  return batch_loss_values, train_stats, valid_stats\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OhU1Zf9owIh"
      },
      "source": [
        "def adam_gradient_descent(X, Y, network, batch_size, eta, max_epochs, loss_fn = CrossEntropy_loss, eps = 1e-8, beta1 = 0.9, \n",
        "                          beta2 = 0.999, weight_decay = 0, regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, \n",
        "                          validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using Adam Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      eps -- Epsilon hyperparameter\n",
        "      beta1 -- Hyperparameter acting as decaying weight for momentum update (standard value 0.9 used)\n",
        "      beta2 -- Hyperparameter acting as decaying weight for learning rate update (standard value 0.999 used)\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (training accuracy, average training loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (validation accuracy, average validation loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "  \n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "  dw, db, v_w, v_b, m_w, m_b, = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                                [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                                [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "  \n",
        "  for epoch in tqdm(range(max_epochs)):  \n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "        batch += 1\n",
        "        Y_true = Y[:,i:i+batch_size]\n",
        "        Y_pred = forward_propagation(network, X[:,i:i+batch_size])\n",
        "        batch_curr_loss = overall_loss(network, Y_pred, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "        dw, db = back_propagation(network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "        batch_loss_values.append(batch_curr_loss)\n",
        "        wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "        for k in range(L):\n",
        "          m_w[k] = m_w[k] * beta1 + (1-beta1) * dw[k]\n",
        "          m_b[k] = m_b[k] * beta1 + (1-beta1) * db[k]\n",
        "          v_w[k] = v_w[k] * beta2 + (1-beta2) * dw[k]**2\n",
        "          v_b[k] = v_b[k] * beta2 + (1-beta2) * db[k]**2\n",
        "          m_w_hat = m_w[k] / (1 - math.pow(beta1, batch))\n",
        "          m_b_hat = m_b[k] / (1 - math.pow(beta1, batch))\n",
        "          v_w_hat = v_w[k] / (1 - math.pow(beta2, batch))\n",
        "          v_b_hat = v_b[k] / (1 - math.pow(beta2, batch))\n",
        "          network[k]['weights'] -= (eta / np.sqrt(v_w_hat + eps)) * m_w_hat\n",
        "          network[k]['biases'] -= (eta / np.sqrt(v_b_hat + eps)) * m_b_hat\n",
        "\n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "  \n",
        "  return batch_loss_values, train_stats, valid_stats\n",
        "  "
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9lk1FkKdZj1"
      },
      "source": [
        "# Nadam optimisation followed from this article : https://arxiv.org/pdf/1609.04747.pdf\n",
        "def nadam_gradient_descent(X, Y, network, batch_size, eta, max_epochs, loss_fn = CrossEntropy_loss, eps = 1e-8, beta1 = 0.9, \n",
        "                           beta2 = 0.999, weight_decay = 0, regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, \n",
        "                           validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using Nadam Accelerated Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      eps -- Epsilon hyperparameter\n",
        "      beta1 -- Hyperparameter acting as decaying weight for momentum update (standard value 0.9 used)\n",
        "      beta2 -- Hyperparameter acting as decaying weight for learning rate update (standard value 0.999 used)\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (training accuracy, average training loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (validation accuracy, average validation loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "\n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "  dw, db, m_w, m_b, v_w, v_b = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                               [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                               [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "\n",
        "\n",
        "  for epoch in tqdm(range(max_epochs)):  \n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "      batch += 1\n",
        "      Y_true = Y[:,i:i+batch_size]\n",
        "      Y_pred = forward_propagation(network, X[:,i:i+batch_size])\n",
        "      batch_curr_loss = overall_loss(network, Y_pred, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "      dw, db = back_propagation(network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "      batch_loss_values.append(batch_curr_loss)\n",
        "      wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "      for k in range(L):\n",
        "        m_w[k] = m_w[k] * beta1 + (1-beta1) * dw[k]\n",
        "        m_b[k] = m_b[k] * beta1 + (1-beta1) * db[k]\n",
        "        v_w[k] = v_w[k] * beta2 + (1-beta2) * dw[k]**2\n",
        "        v_b[k] = v_b[k] * beta2 + (1-beta2) * db[k]**2\n",
        "        m_w_hat = m_w[k] / (1 - math.pow(beta1, batch))\n",
        "        m_b_hat = m_b[k] / (1 - math.pow(beta1, batch))\n",
        "        v_w_hat = v_w[k] / (1 - math.pow(beta2, batch))\n",
        "        v_b_hat = v_b[k] / (1 - math.pow(beta2, batch))\n",
        "        network[k]['weights'] -= (eta / np.sqrt(v_w_hat + eps)) * (m_w_hat + (1-beta1) / (1 - math.pow(beta1, batch)) * dw[k])\n",
        "        network[k]['biases'] -= (eta / np.sqrt(v_b_hat + eps)) * (m_b_hat + (1-beta1) / (1 - math.pow(beta1, batch)) * db[k])\n",
        "\n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "    \n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "  \n",
        "  return batch_loss_values, train_stats, valid_stats\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOmXZeotoxbV"
      },
      "source": [
        "def convert_to_onehot(Y, N) :\n",
        "  # Converting output data Y to onehot representation\n",
        "  Y_onehot = []\n",
        "  for y in Y:\n",
        "    curr_y = [0] * N\n",
        "    curr_y[y] = 1\n",
        "    Y_onehot.append(curr_y)\n",
        "\n",
        "  return np.array(Y_onehot).T\n",
        "\n",
        "def train_validation_split(X, Y, train_to_valid_ratio = 0.9):\n",
        "  # Function to split the given input and output data into training and validation sets in the ratio given by train_to_valid_ratio\n",
        "  assert(train_to_valid_ratio > 0 and train_to_valid_ratio < 1)\n",
        "  np.random.seed(0)\n",
        "  perm = np.random.permutation(trainX.shape[0])\n",
        "  train_size = int(train_to_valid_ratio * len(perm))\n",
        "  train_indices = perm[:train_size]\n",
        "  valid_indices = perm[train_size:]\n",
        "\n",
        "  return X[train_indices], Y[train_indices], X[valid_indices], Y[valid_indices]\n",
        "\n",
        "def transform_NN_IO(X, Y, no_output_class):\n",
        "  # Function to transform the input and output to a form compatible with the Neural Network functions\n",
        "  X_norm = X.reshape(X.shape[0], (X.shape[1]*X.shape[2])).T / 255   # Input Training data with ith column being ith training example's data\n",
        "  Y_onehot = convert_to_onehot(Y, no_output_class)                  # Converting y labels to onehot representation\n",
        "\n",
        "  return X_norm, Y_onehot\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy7GHtEA3Kwv"
      },
      "source": [
        "# Encoding the functions with strings for using in wrapper functions to call them in an easy manner\n",
        "get_grad = {\n",
        "    'sigmoid' : grad_sigmoid,\n",
        "    'tanh' : grad_tanh,\n",
        "    'relu' : grad_relu\n",
        "}\n",
        "\n",
        "get_gd_function = {\n",
        "    'sgd' : sgd_gradient_descent, \n",
        "    'momentum' : momentum_gradient_descent, \n",
        "    'nesterov' : nesterov_gradient_descent, \n",
        "    'rmsprop' : rmsprop_gradient_descent, \n",
        "    'adam' : adam_gradient_descent, \n",
        "    'nadam' : nadam_gradient_descent \n",
        "}\n",
        "\n",
        "get_activ_fn = {\n",
        "    'sigmoid' : sigmoid,\n",
        "    'tanh' : tanh,\n",
        "    'relu' : relu\n",
        "}\n",
        "\n",
        "get_weight_init_fn = {\n",
        "    'random': random_initialisation, \n",
        "    'xavier': xavier_initialisation\n",
        "}\n",
        "\n",
        "get_regularisation_fn = {\n",
        "    'L2': L2_regularisation,\n",
        "    'L1': L1_regularisation\n",
        "}\n",
        "\n",
        "get_grad_reglr_fn = {\n",
        "    'L2': grad_L2_regularisation,\n",
        "    'L1': grad_L1_regularisation\n",
        "}\n",
        "\n",
        "get_output_grad_fn = {\n",
        "    'cross-entropy': Softmax_CrossEntropy_grad,\n",
        "    'squared-error': Softmax_SquaredError_grad\n",
        "}\n",
        "\n",
        "get_loss_fn = {\n",
        "    'cross-entropy': CrossEntropy_loss,\n",
        "    'squared-error': SquaredError\n",
        "}\n",
        "\n",
        "\n",
        "def train_NN(trainX, trainY, optimisation_fn, batch_size, learning_rate, max_epochs, no_hidden_layers, size_hidden_layer, weight_initialisation_fn,\n",
        "             activation_fn, pre_activation_fn = linear, output_fn = softmax, grad_act_fn = grad_sigmoid, \n",
        "             grad_output_fn = Softmax_CrossEntropy_grad, loss_fn = CrossEntropy_loss, weight_decay = 0, regularisation_fn = L2_regularisation,\n",
        "             grad_reglr_fn = grad_L2_regularisation, validX = None, validY = None, testX = None, testY = None):\n",
        "  '''\n",
        "  Function that creates and trains the neural network for the given hyperparameters\n",
        "  Returns :\n",
        "    network -- List of dictionaries representing the neural network\n",
        "    train_stats -- List of tuple of the form (training accuracy, training loss) after each epoch of the training\n",
        "    valid_stats -- List of tuple of the form (validation accuracy, validation loss) after each epoch of the training \n",
        "                   (empty list returned if no validation set given)\n",
        "    test_stat -- Tuple (test accuracy, test loss) for the test set (None returned if no test set given)\n",
        "  ''' \n",
        "  \n",
        "  assert(trainX.shape[1] == trainY.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "  if testY is not None:\n",
        "    assert(testX.shape[1] == testY.shape[1])\n",
        "    \n",
        "  L = no_hidden_layers+1                                # Number of hidden layerws + Output layer in the neural network\n",
        "  n_L = [size_hidden_layer] * (L+1)                     # List of number of neurons in the neural network\n",
        "\n",
        "  n_L[0] = trainX.shape[0]\n",
        "  n_L[L] = trainY.shape[0]\n",
        "\n",
        "  pre_act_fns_L = [pre_activation_fn] * L               # List of Pre-activation functions of the hidden layers and output layer\n",
        "  act_fns_L = [activation_fn] * (L-1) + [output_fn]     # List of Activation functions of the hidden layers and output layer\n",
        "  grad_act_fns_L = [grad_act_fn] * (L-1)                # List of Gradients of the Activation functions, of the hidden layers\n",
        "\n",
        "  network = initialize_network(n_L, pre_act_fns_L, act_fns_L, grad_act_fns_L, grad_output_fn, weight_initialisation_fn)\n",
        "  batch_loss_values, train_stats, valid_stats = optimisation_fn(trainX, trainY, network, batch_size, learning_rate, max_epochs, \n",
        "                                                                loss_fn, weight_decay = weight_decay, regularisation_fn = regularisation_fn, \n",
        "                                                                grad_reglr_fn = grad_reglr_fn, validX = validX, validY = validY)\n",
        "  test_stat = None\n",
        "  if testY is not None: \n",
        "    test_stat = calc_accuracy_loss(network, testX, testY, loss_fn, weight_decay, regularisation_fn)\n",
        "    wandb.log({'test_accuracy': test_stat[0], 'test_loss': test_stat[1]})\n",
        "    # Printing the test accuracy and loss\n",
        "    print(f'Test set accuracy : {test_stat[0]} | Test set loss : {test_stat[1]}')\n",
        "\n",
        "  # Plotting the loss values after each batch of training\n",
        "  plt.plot(batch_loss_values)\n",
        "  plt.show()\n",
        "  # plt.plot(train_stats[:][0])\n",
        "  # plt.show()\n",
        "  # plt.plot(train_stats[:][1])\n",
        "  # plt.show()\n",
        "\n",
        "  return network, train_stats, valid_stats, test_stat"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCamsnTLu6f0"
      },
      "source": [
        "def train_wrapper(trainX, trainY, optimizer, batch_size, learning_rate, max_epochs, no_hidden_layers, size_hidden_layer, \n",
        "                  weight_initialisation, activation, loss, weight_decay = 0,\n",
        "                  validX = None, validY = None, testX = None, testY = None, regularisation = 'L2'):\n",
        "  '''\n",
        "  This is a wrapper for the train_NN function so as to easily train the neural networks with minimal arguments that are necessary.\n",
        "  Arguments :\n",
        "    trainX -- (matrix) Input training data matrix with data as column vectors\n",
        "    trainY -- (matrix) True training output data matrix with data as column vectors\n",
        "    optimizer -- (string) Optimisation function. Takes values only in ['sgd', 'momentum', 'nesterov', 'rmsprop', 'adam', 'nadam']\n",
        "    batch_size -- (int) Batch size for training\n",
        "    learning_rate -- (float) Hyperparameter eta for gradient terms in training\n",
        "    max_epochs -- (int) Maximum number of epochs to train the neural network\n",
        "    no_hidden_layers -- (int) Number of hidden layers in the neural network\n",
        "    size_hidden_layer -- (int) Number of neurons in each hidden layer\n",
        "    weight_initialisation -- (string) Weight initialisation method. Takes values only in ['random', 'xavier']\n",
        "    activation -- (string) Activation function for each neuron. Takes values only in ['relu', 'sigmoid', 'tanh]\n",
        "    loss -- (string) Loss function used. Takes values only in ['cross-entropy', 'squared-error']\n",
        "    weight_decay -- (float) Hyperparameter lambda for regularisation term in training\n",
        "    validX -- (matrix) Input validation data matrix with data as column vectors\n",
        "    validY -- (matrix) True validation output data matrix with data as column vectors\n",
        "    testX -- (matrix) Input testing data matrix with data as column vectors\n",
        "    testY -- (matrix) True testing output data matrix with data as column vectors\n",
        "    regularisation -- (string) Type of regularisation used. Takes values only in ['L2', 'L1']\n",
        "  \n",
        "  Returns :\n",
        "    Output from train_NN function\n",
        "  '''\n",
        "  # Setting the hyperparameters in the wandb\n",
        "  wandb.config.update({'no_hidden_layers': no_hidden_layers, \n",
        "                       'size_hidden_layer': size_hidden_layer,\n",
        "                       'batch_size': batch_size,\n",
        "                       'learning_rate': learning_rate,\n",
        "                       'no_epochs': max_epochs,\n",
        "                       'optimizer': optimizer,\n",
        "                       'weight_decay': weight_decay,\n",
        "                       'weight_initialisation': weight_initialisation, \n",
        "                       'activation_fn': activation,\n",
        "                       'regularisation': regularisation,\n",
        "                       'loss': loss\n",
        "                      })\n",
        "  \n",
        "  # Updating name of run\n",
        "  wandb.run.name = f'hl_{no_hidden_layers}_bs_{batch_size}_ac_{activation}_op_{optimizer}'\n",
        "  wandb.run.save()\n",
        "  \n",
        "  return train_NN(trainX, trainY, get_gd_function[optimizer], batch_size, learning_rate, \n",
        "                  max_epochs, no_hidden_layers, size_hidden_layer, get_weight_init_fn[weight_initialisation],\n",
        "                  get_activ_fn[activation], linear, softmax, get_grad[activation], get_output_grad_fn[loss], \n",
        "                  get_loss_fn[loss], weight_decay, get_regularisation_fn[regularisation], get_grad_reglr_fn[regularisation], \n",
        "                  validX, validY, testX, testY)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKQ4md7QrEuy"
      },
      "source": [
        "# Transforming dataset to a form that can be used in the neural network functions\n",
        "trainX_split, trainY_split, validX_split, validY_split = train_validation_split(trainX, trainy, 0.9)\n",
        "trainX_tr, trainY_tr = transform_NN_IO(trainX_split, trainY_split, N_CLASSES)\n",
        "validX_tr, validY_tr = transform_NN_IO(validX_split, validY_split, N_CLASSES)\n",
        "testX_tr, testY_tr = transform_NN_IO(testX, testy, N_CLASSES)\n",
        "\n",
        "# Questions 2,3 -- Training a neural network with given hyperparameters with cross entropy loss\n",
        "# ---------------- Uncomment the below code to run -----------------\n",
        "\n",
        "# run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "# network, *_ = train_wrapper(trainX_tr, trainY_tr, 'adam', 64, 1e-3, 20, 3, 64, 'xavier', 'relu', 'cross-entropy', \n",
        "#                             0.0005, validX_tr, validY_tr, testX_tr, testY_tr, 'L2')\n",
        "# run.finish()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT5lxNGplX5L"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',                   # Possible search : grid, random, bayes\n",
        "    'metric': {\n",
        "      'name': 'validation_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'no_epochs': {\n",
        "            'values': [5, 10]\n",
        "        },\n",
        "        'no_hidden_layers': {\n",
        "            'values': [3, 4, 5]\n",
        "        },\n",
        "        'size_hidden_layer': {\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'weight_decay' :{\n",
        "            'values': [0, 0.0005, 0.005]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-1, 1e-2, 1e-3]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['sgd', 'momentum', 'nesterov', 'rmsprop', 'adam', 'nadam' ]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [16, 32, 64]\n",
        "        },\n",
        "        'weight_initialisation': {\n",
        "            'values': ['random', 'xavier']\n",
        "        },\n",
        "        'activation_fn': {\n",
        "            'values': ['relu', 'tanh', 'sigmoid']\n",
        "        }\n",
        "    }\n",
        "}\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLYFa9Jh7rU0"
      },
      "source": [
        "def sweep_wrapper(trainX, trainY, validX = None, validY = None, testX = None, testY = None, loss = 'cross-entropy'):\n",
        "  # Wrapper function to call the train_NN function for sweeping with different hyperparameters\n",
        "  # loss - (string) Loss function used. Takes values only in ['cross-entropy', 'squared-error']\n",
        "\n",
        "  # Default values for hyper-parameters we're going to sweep over\n",
        "  config_defaults =  {\n",
        "      'no_epochs': 10,\n",
        "      'no_hidden_layers': 4,\n",
        "      'size_hidden_layer': 128, \n",
        "      'weight_decay' : 0,\n",
        "      'learning_rate': 1e-3,\n",
        "      'optimizer': 'adam',\n",
        "      'batch_size': 64,\n",
        "      'weight_initialisation': 'random', \n",
        "      'activation_fn': 'relu',\n",
        "      'regularisation': 'L2',\n",
        "      'loss': loss\n",
        "  }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  run = wandb.init(config=config_defaults, reinit=True)\n",
        "  \n",
        "  # Config is a variable that holds and saves hyperparameters and inputs\n",
        "  config = wandb.config\n",
        "  wandb.config.update({'no_classes': N_CLASSES})\n",
        "\n",
        "  wandb.run.name = f'hl_{config.no_hidden_layers}_bs_{config.batch_size}_ac_{config.activation_fn}'\n",
        "  wandb.run.save()\n",
        "\n",
        "  # Sweep uses L2 regularisation as default as given in the question\n",
        "  train_NN(trainX, trainY, get_gd_function[config.optimizer], config.batch_size, config.learning_rate, \n",
        "           config.no_epochs, config.no_hidden_layers, config.size_hidden_layer, get_weight_init_fn[config.weight_initialisation],\n",
        "           get_activ_fn[config.activation_fn], linear, softmax, get_grad[config.activation_fn], \n",
        "           get_output_grad_fn[loss], get_loss_fn[loss], config.weight_decay, L2_regularisation, grad_L2_regularisation, \n",
        "           validX, validY, testX, testY)\n",
        "  \n",
        "  run.finish()\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTMh4OI7HGzC"
      },
      "source": [
        "# Questions 4-6 -- Running a sweep across different hyperparameter configurations with cross entropy as the loss function\n",
        "# ---------------- Uncomment the below code to run -----------------\n",
        "\n",
        "# sweep_id = wandb.sweep(sweep_config, entity=\"abisheks\", project=\"assignment1\")\n",
        "# wandb.agent(sweep_id, lambda : sweep_wrapper(trainX_tr, trainY_tr, validX_tr, validY_tr, testX_tr, testY_tr, 'cross-entropy'))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHHZemXkdwVb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "05bd9c87eb974f67a078ecd909baee91",
            "460fb81582184330a749e0d954cd1a3b",
            "1725c98a23dc42dc8dcfcf746a04ec9b",
            "880151db24794901b4989c903f2b9799",
            "4bce9a6bc3d141039ca6230b65e2c16d",
            "2cbef3ab3ec742c1a62c6fdb954ca9de",
            "a65a06945c8e4a28af0066c4fcabce52",
            "6e9b5daaa71b4fb48834e2b220ccefb2",
            "f5f2917e223448f0b376e9167c9de07c",
            "66b0ab3949404e9e8b42786a02d5a144",
            "bb8d4df2a27e4acea430b2e570d7f0fc",
            "2655a6e7cd1c4ae0aa40e256454102eb",
            "c9db0de8273d47f385f1341c4446652a",
            "9d457176854249e6866e1d58e2f5d8e5",
            "daafb11950d84a7bac61cadd4e7c6619",
            "8390919e84054f6ca73247035857e703"
          ]
        },
        "outputId": "c1f93bc6-3883-48d3-bf70-942565bd4c9d"
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(network, X, Y):\n",
        "  # Function to plot the confusion matrix for a given trained network, input (X) and true output (Y)\n",
        "  Y_pred = forward_propagation(network, X)\n",
        "  cm = confusion_matrix(np.argmax(Y, axis=0), np.argmax(Y_pred, axis=0))\n",
        "\n",
        "  df_cm = pd.DataFrame(cm, [IMG_LABELS[i] for i in range(cm.shape[0])], [IMG_LABELS[i] for i in range(cm.shape[0])])\n",
        "  \n",
        "  # Plotting the confusion matrix\n",
        "  plt.figure(figsize=(10,10))\n",
        "  sn.set(font_scale=1.0) # for label size\n",
        "  sn.heatmap(df_cm, annot=True, \n",
        "            annot_kws={\"size\": 16}, cmap='YlGnBu', fmt='g'\n",
        "            )\n",
        "  plt.ylabel(r'$Y_{true}$', fontsize=18)\n",
        "  plt.xlabel(r'$Y_{pred}$', fontsize=18)\n",
        "\n",
        "  # Logging the confusion matrix to WANDB\n",
        "  wandb.log({'Confusion Matrix': wandb.Image(plt, caption = 'hl_4_bs_64_ac_relu_op_momentum')})\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "# Question 7 -- Training the neural network and printing the test accuracy and loss for the best choice of hyperparameters with cross entropy loss.\n",
        "#               And plotting the confusion matrix for the output of this trained network\n",
        "# ---------------- Uncomment the below code to run -----------------\n",
        "\n",
        "run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "network, *_ = train_wrapper(trainX_tr, trainY_tr, 'momentum', 64, 1e-2, 10, 4, 128, 'xavier', 'relu', 'cross-entropy', \n",
        "                            0.0005, validX_tr, validY_tr, testX_tr, testY_tr, 'L2')\n",
        "plot_confusion_matrix(network, testX_tr, testY_tr)\n",
        "run.finish()\n",
        "\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:3jsxf8jv) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 142<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05bd9c87eb974f67a078ecd909baee91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210312_142204-3jsxf8jv/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210312_142204-3jsxf8jv/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">lucky-elevator-1110</strong>: <a href=\"https://wandb.ai/abisheks/assignment1/runs/3jsxf8jv\" target=\"_blank\">https://wandb.ai/abisheks/assignment1/runs/3jsxf8jv</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:3jsxf8jv). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.22<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">splendid-violet-1111</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment1\" target=\"_blank\">https://wandb.ai/abisheks/assignment1</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/abisheks/assignment1/runs/c1mnksws\" target=\"_blank\">https://wandb.ai/abisheks/assignment1/runs/c1mnksws</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210312_142353-c1mnksws</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n",
            "100%|██████████| 10/10 [01:03<00:00,  6.37s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy : 0.8737 | Test set loss : 0.5016692806338972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 223<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5f2917e223448f0b376e9167c9de07c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210312_142353-c1mnksws/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210312_142353-c1mnksws/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>batch</td><td>8440</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>batch_loss</td><td>0.39689</td></tr><tr><td>_runtime</td><td>68</td></tr><tr><td>_timestamp</td><td>1615559105</td></tr><tr><td>_step</td><td>8451</td></tr><tr><td>validation_accuracy</td><td>0.87367</td></tr><tr><td>accuracy</td><td>0.8952</td></tr><tr><td>validation_loss</td><td>0.49687</td></tr><tr><td>loss</td><td>0.42821</td></tr><tr><td>test_accuracy</td><td>0.8737</td></tr><tr><td>test_loss</td><td>0.50167</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>batch_loss</td><td>█▅▅▅▃▃▅▃▄▄▃▄▃▃▂▃▂▃▂▃▃▅▁▂▃▁▂▂▂▂▃▃▂▁▁▁▂▂▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>validation_accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>validation_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">splendid-violet-1111</strong>: <a href=\"https://wandb.ai/abisheks/assignment1/runs/c1mnksws\" target=\"_blank\">https://wandb.ai/abisheks/assignment1/runs/c1mnksws</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoJeGwK0dix_"
      },
      "source": [
        "# Questions 8 -- Running a sweep across different hyperparameter configurations with squared error as the loss function\n",
        "# ---------------- Uncomment the below code to run -----------------\n",
        "\n",
        "# sweep_id = wandb.sweep(sweep_config, entity=\"abisheks\", project=\"assignment1\")\n",
        "# wandb.agent(sweep_id, lambda : sweep_wrapper(trainX_tr, trainY_tr, validX_tr, validY_tr, testX_tr, testY_tr, 'squared-error'))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Waci5hIhd7hJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919016e2-d588-420a-a58b-c1052e71be93"
      },
      "source": [
        "# Loading the MNIST dataset\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Load dataset (train data and test data)\n",
        "(trainX_2, trainy_2), (testX_2, testy_2) = mnist.load_data()\n",
        "\n",
        "# Summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
        "\n",
        "# Number of classes in the MNIST (Digit) dataset\n",
        "N_CLASSES_2 = np.unique(trainy_2).shape[0]    # 10 as known from the keras documentation\n",
        "\n",
        "# Transforming dataset to a form that can be used in the neural network functions\n",
        "trainX_split_2, trainY_split_2, validX_split_2, validY_split_2 = train_validation_split(trainX_2, trainy_2, 0.9)\n",
        "trainX_tr_2, trainY_tr_2 = transform_NN_IO(trainX_split_2, trainY_split_2, N_CLASSES_2)\n",
        "validX_tr_2, validY_tr_2 = transform_NN_IO(validX_split_2, validY_split_2, N_CLASSES_2)\n",
        "testX_tr_2, testY_tr_2 = transform_NN_IO(testX_2, testy_2, N_CLASSES_2)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdlsRGUiWibN"
      },
      "source": [
        "# Training neural networks for the MNIST dataset\n",
        "\n",
        "def do_mnist_cross_entropy(trainX, trainY, validX = None, validY = None, testX = None, testY = None):\n",
        "  # Function to train neural network (with cross entropy loss function) for MNIST dataset with three best configuration of hyperparameters, \n",
        "  # predicted from experiments on fashion-MNIST \n",
        "  run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "  network, *_ = train_wrapper(trainX, trainY, 'momentum', 64, 1e-2, 10, 4, 128, 'xavier', 'relu', 'cross-entropy', \n",
        "                              0.0005, validX, validY, testX, testY, 'L2')\n",
        "  run.finish()\n",
        "\n",
        "  run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "  network, *_ = train_wrapper(trainX, trainY, 'momentum', 64, 1e-2, 10, 4, 64, 'xavier', 'relu', 'cross-entropy', \n",
        "                              0.0005, validX, validY, testX, testY, 'L2')\n",
        "  run.finish()\n",
        "\n",
        "  run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "  network, *_ = train_wrapper(trainX, trainY, 'nadam', 64, 1e-2, 10, 4, 64, 'xavier', 'relu', 'cross-entropy', \n",
        "                              0.0005, validX, validY, testX, testY, 'L2')\n",
        "  run.finish()\n",
        "\n",
        "\n",
        "def do_mnist_squared_error(trainX, trainY, validX = None, validY = None, testX = None, testY = None):\n",
        "  # Function to train neural network (with cross entropy loss function) for MNIST dataset with three best configuration of hyperparameters, \n",
        "  # predicted from experiments on fashion-MNIST \n",
        "  run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "  network, *_ = train_wrapper(trainX, trainY, 'adam', 64, 1e-3, 10, 4, 128, 'random', 'relu', 'squared-error', \n",
        "                              0, validX, validY, testX, testY, 'L2')\n",
        "  run.finish()\n",
        "\n",
        "  run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "  network, *_ = train_wrapper(trainX, trainY, 'nadam', 64, 1e-3, 10, 4, 128, 'random', 'relu', 'squared-error', \n",
        "                              0, validX, validY, testX, testY, 'L2')\n",
        "  run.finish()\n",
        "\n",
        "  run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "  network, *_ = train_wrapper(trainX, trainY, 'momentum', 64, 1e-1, 10, 4, 128, 'xavier', 'relu', 'squared-error', \n",
        "                              0, validX, validY, testX, testY, 'L2')\n",
        "  run.finish()\n",
        "\n",
        "\n",
        "# Question 10 -- Training neural networks on MNIST dataset after experimenting with fashion-MNIST dataset and figuring out 3 best hyperparameter configurations\n",
        "# ---------------- Uncomment the below code to run -----------------\n",
        "\n",
        "# # For cross entropy loss\n",
        "# do_mnist_cross_entropy(trainX_tr_2, trainY_tr_2, validX_tr_2, validY_tr_2, testX_tr_2, testY_tr_2)\n",
        "# # For squared error loss\n",
        "# do_mnist_squared_error(trainX_tr_2, trainY_tr_2, validX_tr_2, validY_tr_2, testX_tr_2, testY_tr_2)"
      ],
      "execution_count": 74,
      "outputs": []
    }
  ]
}