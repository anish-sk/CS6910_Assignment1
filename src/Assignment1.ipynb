{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VectorizeAssignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd13f569360b419a8b5e646c2efaff6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad14abf4b0094727b4f80b1d3e525c03",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d347893b01f94b01924ba44b21f37ff2",
              "IPY_MODEL_848b38c08e194923a05a7ef9f05ce7f9"
            ]
          }
        },
        "ad14abf4b0094727b4f80b1d3e525c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d347893b01f94b01924ba44b21f37ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_0b81e30c4c364e63aa8b4d28a904607f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ca3adb1a208443abc78fce17f85896e"
          }
        },
        "848b38c08e194923a05a7ef9f05ce7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ce19490681f34ce1a6cb4fef3d1c56db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_106676763303483a8e5c705abb61cd08"
          }
        },
        "0b81e30c4c364e63aa8b4d28a904607f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ca3adb1a208443abc78fce17f85896e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce19490681f34ce1a6cb4fef3d1c56db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "106676763303483a8e5c705abb61cd08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b5ab8fe81c248b0b9e3b5df324f3d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d095224745734cf6afc33586ca6238f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1378e4fd092f48d585e52c945d71cca4",
              "IPY_MODEL_d16f16ff8359445889d2f0c45ed1e385"
            ]
          }
        },
        "d095224745734cf6afc33586ca6238f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1378e4fd092f48d585e52c945d71cca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_c07bb1a8480a40f3b695fa3d87a9d606",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5aa85d8732094e4fb3dff6a757e8490d"
          }
        },
        "d16f16ff8359445889d2f0c45ed1e385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_520b895e0c4b4304bad644188722c90f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_851c6db52e5544caa15446e3f83ca045"
          }
        },
        "c07bb1a8480a40f3b695fa3d87a9d606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5aa85d8732094e4fb3dff6a757e8490d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "520b895e0c4b4304bad644188722c90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "851c6db52e5544caa15446e3f83ca045": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bbcaa033cae47c5b05246c8686dbc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0bd78c33fcc74b18befd665a9127e667",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc00c5e74a9244debba5d062c1a03f77",
              "IPY_MODEL_82af286ddd4247c7807f5918e13c52bd"
            ]
          }
        },
        "0bd78c33fcc74b18befd665a9127e667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc00c5e74a9244debba5d062c1a03f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_e8664d3e75104daf9059aa36a663e55c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.04MB of 0.04MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc379116e12e4024bd024a912f419f42"
          }
        },
        "82af286ddd4247c7807f5918e13c52bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0cc17d15c654474ba33216f4c7101d85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab7a466bda8144c39ce96331ddc1fbe3"
          }
        },
        "e8664d3e75104daf9059aa36a663e55c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc379116e12e4024bd024a912f419f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cc17d15c654474ba33216f4c7101d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab7a466bda8144c39ce96331ddc1fbe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anish-sk/CS6910_Assignment1/blob/master/src/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DMWBsOgIyM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bbc8bbc-bc91-4f20-82db-a425f654b632"
      },
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login 6746f968d95eb71e281d6c7772a0469574430408"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/ae/79374d2b875e638090600eaa2a423479865b7590c53fb78e8ccf6a64acb1/wandb-0.10.22-py2.py3-none-any.whl (2.0MB)\n",
            "\r\u001b[K     |▏                               | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 28.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 22.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 26.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 25.2MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 27.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 18.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 81kB 19.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 18.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 102kB 18.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 112kB 18.1MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 18.1MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 18.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 143kB 18.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 153kB 18.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 163kB 18.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 174kB 18.1MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 18.1MB/s eta 0:00:01\r\u001b[K     |███                             | 194kB 18.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 204kB 18.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 215kB 18.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 225kB 18.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 235kB 18.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 245kB 18.1MB/s eta 0:00:01\r\u001b[K     |████                            | 256kB 18.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 266kB 18.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 276kB 18.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 286kB 18.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 296kB 18.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 307kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 317kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 327kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 337kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 348kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 358kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 368kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 378kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 389kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 399kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 409kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 419kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 430kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 440kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 450kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 460kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 471kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 481kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 491kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 501kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 512kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 522kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 532kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 542kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 552kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 563kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 573kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 583kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 593kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 604kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 614kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 624kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 634kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 645kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 655kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 665kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 675kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 686kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 696kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 706kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 716kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 727kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 737kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 747kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 757kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 768kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 778kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 788kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 798kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 808kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 819kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 829kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 839kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 849kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 860kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 870kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 880kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 890kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 901kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 911kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 921kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 931kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 942kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 952kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 962kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 972kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 983kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 993kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.1MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.1MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.1MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.1MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.1MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.1MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.1MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.1MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.2MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.2MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.2MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.2MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.2MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.2MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.2MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.2MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.2MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.3MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.3MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.3MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.3MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.3MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.3MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.3MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.4MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.4MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.4MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.4MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.4MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.4MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.4MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.4MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.5MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.5MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.5MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.5MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.5MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.5MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.5MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.5MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.5MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.6MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.6MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.6MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.6MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.6MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.6MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.6MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.6MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.6MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.7MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.7MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.7MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.7MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.7MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.7MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.7MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.8MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.8MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.8MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.8MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.8MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.8MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.8MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.8MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.8MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.9MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.9MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.9MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.9MB 18.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.9MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.9MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.9MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.9MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.9MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.9MB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.0MB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.0MB 18.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 54.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.0.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=fd34b10e6301ea2493c4dc2037850abfcf36cac253d3fffe657aea7215971663\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=bb151e90ada51b0dd33d19cfb1cdddc850d0c0aa5458a6c726bc62b29370f930\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: configparser, sentry-sdk, smmap, gitdb, GitPython, pathtools, shortuuid, docker-pycreds, subprocess32, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-3.0.5 subprocess32-3.5.4 wandb-0.10.22\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd2ZVTXmJfT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d5abec-ba20-4097-ff1f-39b142e49f37"
      },
      "source": [
        "# Init wandb\n",
        "import wandb\n",
        "\n",
        "# run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "# Loading the fashion mnist dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "# Setting seed value\n",
        "np.random.seed(1)\n",
        "\n",
        "# Load dataset (train data and test data)\n",
        "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n",
        "\n",
        "# Summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtNK58VvJrZO"
      },
      "source": [
        "\n",
        "# Number of classes in the Fashion-MNIST dataset\n",
        "N_CLASSES = np.unique(trainy).shape[0]    # 10 as known from the keras documentation\n",
        "\n",
        "# Captions/Labels for the output classes present in Fashion-MNIST dataset\n",
        "IMG_LABELS = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "\n",
        "def getSampleImages(nClass, imgLabels, X, y, nSamples):\n",
        "  '''\n",
        "  The function takes few samples of each class from the dataset provided and passes it to the WANDB for it log the images\n",
        "\n",
        "  Arguments :\n",
        "    nClass -- Number of output classes in the dataset\n",
        "    imgLabels -- List of labels for the output classes (numbered from 0 to nClass - 1)\n",
        "    X -- The input data containing images in the form of matrices\n",
        "    y -- The output data containing the class to which an input belongs\n",
        "    nSamples -- Number of samples of each class to be taken. If that many samples not present in dataset, maximum number of samples present (from that class) will be taken\n",
        "\n",
        "  Returns :\n",
        "    -- None --\n",
        "  '''\n",
        "\n",
        "  # Initialise empty list to store the input data sampled from each class\n",
        "  sampleImgsX = [[] for _ in range(nClass)]\n",
        "\n",
        "  # Take 3 sample images from each class\n",
        "  for i in range(y.shape[0]):\n",
        "    if len(sampleImgsX[y[i]]) < nSamples :\n",
        "      sampleImgsX[y[i]].append(X[i])\n",
        "\n",
        "\n",
        "  # Getting a list of sample images of each class to be saved to wandb\n",
        "  sampleImgsList = []\n",
        "  for i in range(nClass):\n",
        "    for j in range(3):\n",
        "      sampleImgsList.append(wandb.Image(sampleImgsX[i][j], caption = imgLabels[i]))\n",
        "\n",
        "  np.random.shuffle(sampleImgsList)\n",
        "  wandb.log({\"example\" : sampleImgsList})\n",
        "\n",
        "\n",
        "# Question 1 : Show 3 sample images from training set of downloaded Fashion-MNIST dataset in WANDB\n",
        "# getSampleImages(N_CLASSES, IMG_LABELS, trainX, trainy, 3)\n",
        "# run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbufY1DHNQdm"
      },
      "source": [
        "def relu(X):\n",
        "  # Calculates the Rectified Linear Unit (ReLU) function\n",
        "  return np.maximum(X,0)\n",
        "\n",
        "def sigmoid(X):\n",
        "  # Calculates the sigmoid function\n",
        "  return np.exp(-np.logaddexp(0, -X))\n",
        "\n",
        "def softmax(X):\n",
        "  # Calculates the softmax function\n",
        "  e_X = np.exp(X - np.max(X, axis = 0))\n",
        "  return e_X / e_X.sum(axis = 0)\n",
        "\n",
        "def tanh(X):\n",
        "  return np.tanh(X)\n",
        "\n",
        "def linear(W, X, b):\n",
        "  # Calculates the linear function\n",
        "  return W @ X + b\n",
        "\n",
        "def grad_relu(X):\n",
        "  # Calculates the gradient of Rectified Linear Unit (ReLU) function\n",
        "  return X > 0\n",
        "\n",
        "def grad_sigmoid(X):\n",
        "  # Calculates the gradient of sigmoid function\n",
        "  return sigmoid(X) * (1 - sigmoid(X))\n",
        "\n",
        "def grad_tanh(X):\n",
        "  # Calculates the gradient of tanh function\n",
        "  return 1 - np.tanh(X)**2\n",
        "\n",
        "def Softmax_CrossEntropy_grad(Y_pred, Y):\n",
        "  # Calculates the gradient of the output layer with softmax activation and cross entropy loss\n",
        "  # layer -- The dictionary for the output layer contianing info about it\n",
        "  # y -- True output\n",
        "  return -(Y - Y_pred)\n",
        "\n",
        "def Softmax_SquaredError_grad(Y_pred, Y):\n",
        "  return ((Y_pred - Y) - ((Y_pred - Y) * Y_pred).sum(axis = 0)) * Y_pred "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX_08I3AJaiF"
      },
      "source": [
        "def random_initialisation(shape):\n",
        "  # Initialising a random matrix with given dimensions (shape) as tuple\n",
        "  return np.random.randn(*shape)*0.1\n",
        "\n",
        "def xavier_initialisation(shape):\n",
        "  # Initialising a matrix by xavier initialisation with given dimensions (shape) as tuple\n",
        "  bound = (6/(shape[0]+shape[1]))**(0.5)\n",
        "  return bound*(2*np.random.rand(*shape)-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3rWXP7YMDOS"
      },
      "source": [
        "def initialize_network(n_L, preActFns_L, actFns_L, gradActFns_L, gradOutputFn, weight_initialisation):\n",
        "  '''\n",
        "  The function initializes the neural network and the appropriate parameters\n",
        "  \n",
        "  Arguments :\n",
        "    n_L -- an array whose ith element represents the number of neurons in the ith layer (0 - Input Layer, last element - Output Layer)\n",
        "    preActFns_L -- an array who ith element is the Pre Activation function of the (i+1)th layer of the neural network\n",
        "    actFns_L -- an array who ith element is the Activation function of the (i+1)th layer of the neural network\n",
        "    gradActFns_L -- an array who ith element is the gradient of the Activation function of the (i+1)th layer of the neural network\n",
        "    gradOutputFn -- Function to calculate gradients wrt a_L (output layer) in back-propagation\n",
        "    weight_initialisation -- Function to initialise weights of the layers\n",
        "  \n",
        "  Returns :\n",
        "    network -- the initialized network as an array of dictionaries for the hidden and output layers of the neural network\n",
        "  '''\n",
        "\n",
        "  L = len(n_L)-1\n",
        "\n",
        "  assert(L >= 1)\n",
        "  assert(len(preActFns_L) == L)\n",
        "  assert(len(actFns_L) == L)\n",
        "\n",
        "  network = list()\n",
        "  for i in range(1,L+1):\n",
        "    # Dictionary for each layer representing it's constituents\n",
        "    layer = {'weights':weight_initialisation((n_L[i],n_L[i-1])),  # Weight matrix for (i-1)th to ith layer transition\n",
        "             'biases':np.zeros((n_L[i],1)),                       # Bias vector for (i-1)th to ith layer transition\n",
        "             'pre_activation_fn':preActFns_L[i-1],                # Pre-activation function for neurons of the ith layer\n",
        "             'activation_fn':actFns_L[i-1],                       # Activation function for neurons of the ith layer             \n",
        "             'no_neurons':n_L[i],                                 # Number of neurons in ith layer\n",
        "             'cache': []                                          # Array of cached pre-activation and activation output for each layer to be used in back-propagation (will be filled in forward-propagation)\n",
        "            }\n",
        "    network.append(layer)\t\n",
        "    if i < L:\n",
        "      network[-1]['grad_activation_fn'] = gradActFns_L[i-1]       # Function calculating Gradient of the Activation function for the ith (hidden) layer\n",
        "  \n",
        "  network[-1]['grad_output_fn'] = gradOutputFn                    # Function calculating Gradient of the Output layer (Gradient of Loss function wrt a_L)\n",
        "\n",
        "  return network\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sDSj4aTPeTw"
      },
      "source": [
        "def pre_activation(H_prev, W, b, pre_activation_fn):\n",
        "  # Calculates the pre-activation output and caches the required values. Returns the output and cache.\n",
        "\n",
        "  A = pre_activation_fn(W, H_prev, b)\n",
        "  \n",
        "  assert(A.shape[0] == W.shape[0])\n",
        "  pre_act_cache = H_prev                    # Caching the pre-activation ouptut to be used in backpropagation\n",
        "\n",
        "  return A, pre_act_cache\n",
        "\n",
        "def feedforward_neuron(H_prev, W, b, activation_fn, pre_activation_fn):\n",
        "  # Calculates the activation output (using the pre-activation function above) and caches the required values. Returns the output and cache.\n",
        "\n",
        "  A, pre_activation_cache = pre_activation(H_prev, W, b, pre_activation_fn)\n",
        "  H = activation_fn(A)\n",
        "  \n",
        "  assert (H.shape[0] == W.shape[0])\n",
        "  cache = (pre_activation_cache, A)         # Caching the pre-activation and activation output to use it in back-propagation\n",
        "\n",
        "  return H, cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVFXPTolPf5v"
      },
      "source": [
        "def forward_propagation(network, X):\n",
        "    \"\"\"\n",
        "    Implement forward propagation for the given neural network\n",
        "    \n",
        "    Arguments :\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      X -- Input data from the training set as a matrix with ith column representing ith input training data\n",
        "    \n",
        "    Returns :\n",
        "      Output from the neural network as a matrix with ith column representing output of ith input data\n",
        "    \"\"\"\n",
        "\n",
        "    H = X                         # Initialising H to input\n",
        "    L = len(network)              # Number of (hidden + output) layers in the neural network\n",
        "\n",
        "    for l in range(0, L):\n",
        "        H_prev = H \n",
        "        H, cache = feedforward_neuron(H_prev, network[l]['weights'], network[l]['biases'], network[l]['activation_fn'], network[l]['pre_activation_fn'])\n",
        "        network[l]['cache'] = cache\n",
        "    \n",
        "    assert(H.shape[0] == (network[L-1]['no_neurons']))\n",
        "        \n",
        "    return H\n",
        "\n",
        "# HL = forward_propagation(trainX_reshaped, network)          # HL -- output from the neural network\n",
        "# print(HL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCQvQGxcaCTC"
      },
      "source": [
        " def back_propagation(network, Y, Y_pred, weight_decay, grad_reglr_fn):\n",
        "  \"\"\"\n",
        "    Implement backward propagation for the given neural network\n",
        "    \n",
        "    Arguments :\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      Y -- True output matrix with ith column representing true output of ith input data\n",
        "      Y_pred -- Output of neural network as a matrix in the same form as Y\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "    \n",
        "    Returns :\n",
        "      H -- Output from the neural network\n",
        "  \"\"\"\n",
        "\n",
        "  L = len(network)\n",
        "  assert(Y.shape[1] == Y_pred.shape[1])\n",
        "  M = Y.shape[1]\n",
        "\n",
        "  # Gradients wrt output layer (a_L)\n",
        "  grad_a_k_L = network[L-1]['grad_output_fn'](Y_pred, Y)\n",
        "\n",
        "  # Initialising gradients to be calculated in the loop below\n",
        "  grad_w_L = [np.zeros(2)] * L\n",
        "  grad_b_L = [np.zeros(2)] * L\n",
        "  grad_h_prev_L, grad_a_prev_L = 0, 0\n",
        "\n",
        "  for k in range(L-1,-1,-1):\n",
        "    # Gradients wrt Weights (W_k)\n",
        "    grad_w_L[k] = (grad_a_k_L @ network[k]['cache'][0].T / M) + weight_decay * grad_reglr_fn(network[k]['weights'])\n",
        "\n",
        "    # Gradients wrt Biases (b_k)\n",
        "    grad_b_L[k] = np.mean(grad_a_k_L, axis=1)\n",
        "    grad_b_L[k] = grad_b_L[k].reshape((grad_b_L[k].shape[0], 1))\n",
        "    \n",
        "    # Gradients wrt hidden layer\n",
        "    # Gradients wrt h_(k-1)\n",
        "    grad_h_prev_L = network[k]['weights'].T @ grad_a_k_L\n",
        "\n",
        "    # Gradients wrt a_(k-1)\n",
        "    if(k > 0):\n",
        "      grad_act_fn_prev = network[k-1]['grad_activation_fn'](network[k-1]['cache'][1])\n",
        "      grad_a_prev_L = grad_h_prev_L * grad_act_fn_prev\n",
        "\n",
        "    grad_a_k_L = grad_a_prev_L\n",
        "\n",
        "  return grad_w_L, grad_b_L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knKqQELwYpeb"
      },
      "source": [
        "def L2_regularisation(network):\n",
        "  # Function that returns L2 regularisation loss for the given network\n",
        "  L = len(network)\n",
        "  ans = 0\n",
        "  for k in range(L):\n",
        "    ans += np.sum(network[k]['weights'] ** 2)\n",
        "  \n",
        "  return ans\n",
        "\n",
        "def L1_regularisation(network):\n",
        "  # Function that returns L1 regularisation loss for the given network\n",
        "  L = len(network)\n",
        "  ans = 0\n",
        "  for k in range(L):\n",
        "    ans += np.sum(np.absolute(network[k]['weights']))\n",
        "  \n",
        "  return ans\n",
        "\n",
        "def grad_L2_regularisation(W):\n",
        "  # Function that returns L2 regularisation gradient for the given Weight matrix / tensor\n",
        "  return 2 * W\n",
        "\n",
        "def grad_L1_regularisation(W):\n",
        "  # Function that returns L1 regularisation gradient for the given Weight matrix / tensor\n",
        "  return np.sign(W)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyD4oPSIL19s"
      },
      "source": [
        "def CrossEntropy_loss(Y_pred, Y_true):\n",
        "  # Function that returns cross entropy loss\n",
        "  assert(Y_pred.shape[1] == Y_true.shape[1])\n",
        "  M = Y_pred.shape[1]\n",
        "  return -(Y_true * np.log(Y_pred)).sum() / M\n",
        "\n",
        "def SquaredError(Y_pred, Y_true):\n",
        "  # Function that returns mean squared loss\n",
        "  assert(Y_pred.shape[1] == Y_true.shape[1])\n",
        "  M = Y_pred.shape[1]\n",
        "  return ((Y_true - Y_pred) ** 2).sum() / (2.0 * M)\n",
        "\n",
        "def overall_loss(network, Y_pred, Y_true, loss_fn = CrossEntropy_loss, weight_decay = 0, regularisation_fn = L2_regularisation):\n",
        "  # Function that returns overall loss (Output layer cost function + Regularisation) for the network\n",
        "  return loss_fn(Y_pred, Y_true) + weight_decay * regularisation_fn(network)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6abLgZ7KRtM"
      },
      "source": [
        "  def calc_accuracy_loss(network, X, Y, loss_fn = CrossEntropy_loss, weight_decay = 0, regularisation_fn = L2_regularisation):\n",
        "    # Function that returns the accuracy and loss for a given network\n",
        "    Y_pred = forward_propagation(network, X)\n",
        "    loss = overall_loss(network, Y_pred, Y, loss_fn, weight_decay, regularisation_fn)\n",
        "    assert(X.shape[1] == Y.shape[1])\n",
        "    M = X.shape[1]\n",
        "    accuracy = np.sum(np.argmax(Y_pred, axis = 0) == np.argmax(Y, axis = 0)) / M\n",
        "    return accuracy, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXZpq0rM0Vvf"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def sgd_gradient_descent(X, Y, network, batch_size = 1, eta = 5e-2, max_epochs = 100, loss_fn = CrossEntropy_loss, weight_decay = 0, \n",
        "                         regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using Vanilla/Batch Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input training data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True training output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "\n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "  dw, db = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "  \n",
        "  for epoch in tqdm(range(max_epochs)):        \n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "      batch += 1\n",
        "      Y_true = Y[:,i:i+batch_size]\n",
        "      Y_pred = forward_propagation(network, X[:,i:i+batch_size])\n",
        "      batch_curr_loss = overall_loss(network, Y_pred, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "      dw, db = back_propagation(network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "      batch_loss_values.append(batch_curr_loss)\n",
        "      wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "      for k in range(L):\n",
        "        network[k]['weights'] -= eta * dw[k]\n",
        "        network[k]['biases'] -= eta * db[k]\n",
        "    \n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "\n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "  \n",
        "  return batch_loss_values, train_stats, valid_stats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwQkfH0-oz4A"
      },
      "source": [
        "def momentum_gradient_descent(X, Y, network, batch_size = 1, eta = 5e-2, max_epochs = 100, loss_fn = CrossEntropy_loss, beta = 0.9, weight_decay = 0, \n",
        "                              regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using Momentum Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      beta -- Hyperparameter to tune dependency of gradient on history\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "\n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "  dw, db, m_w, m_b = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                     [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "\n",
        "  for epoch in tqdm(range(max_epochs)):  \n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "      batch += 1\n",
        "      Y_true = Y[:,i:i+batch_size]\n",
        "      Y_pred = forward_propagation(network, X[:,i:i+batch_size])\n",
        "      batch_curr_loss = overall_loss(network, Y_pred, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "      dw, db = back_propagation(network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "      batch_loss_values.append(batch_curr_loss)\n",
        "      wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "      for k in range(L):\n",
        "        m_w[k] = m_w[k] * beta + dw[k] * eta\n",
        "        m_b[k] = m_b[k] * beta + db[k] * eta\n",
        "        network[k]['weights'] -= m_w[k]\n",
        "        network[k]['biases'] -= m_b[k]\n",
        "  \n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "\n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "  \n",
        "  return batch_loss_values, train_stats, valid_stats\n",
        "\n",
        "\n",
        "def nesterov_gradient_descent(X, Y, network, batch_size = 1, eta = 5e-2, max_epochs = 100, loss_fn = CrossEntropy_loss, beta = 0.9, weight_decay=0, \n",
        "                              regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using Nesterov Accelerated Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      beta -- Hyperparameter to tune dependency of gradient on history\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "  dw, db, m_w, m_b = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                     [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "\n",
        "  lookahead_network = network[:]\n",
        "\n",
        "  for epoch in tqdm(range(max_epochs)):\n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "      batch += 1\n",
        "      Y_true = Y[:,i:i+batch_size]\n",
        "      Y_pred_org = forward_propagation(network, X[:,i:i+batch_size])\n",
        "      batch_curr_loss = overall_loss(network, Y_pred_org, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "      Y_pred = forward_propagation(lookahead_network, X[:,i:i+batch_size])\n",
        "      dw, db = back_propagation(lookahead_network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "      batch_loss_values.append(batch_curr_loss)\n",
        "      wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "      for k in range(L):\n",
        "        m_w[k] = m_w[k] * beta + dw[k] * eta\n",
        "        m_b[k] = m_b[k] * beta + db[k] * eta\n",
        "        network[k]['weights'] -= m_w[k]\n",
        "        network[k]['biases'] -= m_b[k] \n",
        "        lookahead_network[k]['weights'] -= (eta * dw[k] + beta * m_w[k])\n",
        "        lookahead_network[k]['biases'] -= (eta * db[k] + beta * m_b[k])\n",
        "\n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "    \n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "\n",
        "  return batch_loss_values, train_stats, valid_stats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K2eWRLqPUiw"
      },
      "source": [
        "def rmsprop_gradient_descent(X, Y, network, batch_size = 1, eta = 5e-2, max_epochs = 100, loss_fn = CrossEntropy_loss, eps = 1e-8, beta = 0.9,\n",
        "                             weight_decay=0, regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, \n",
        "                             validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using RMSProp Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      eps -- Epsilon hyperparameter\n",
        "      beta -- Hyperparameter acting as decaying weight for learning rate update\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "    \n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "\n",
        "  dw, db, v_w, v_b = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                     [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "\n",
        "  for epoch in tqdm(range(max_epochs)):  \n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "        batch += 1\n",
        "        Y_true = Y[:,i:i+batch_size]\n",
        "        Y_pred = forward_propagation(network, X[:,i:i+batch_size])\n",
        "        batch_curr_loss = overall_loss(network, Y_pred, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "        dw, db = back_propagation(network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "        batch_loss_values.append(batch_curr_loss)\n",
        "        wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "        for k in range(L):\n",
        "          v_w[k] = v_w[k] * beta + (1-beta) * dw[k]**2\n",
        "          v_b[k] = v_b[k] * beta + (1-beta) * db[k]**2\n",
        "          network[k]['weights'] -= (eta / np.sqrt(v_w[k] + eps)) * dw[k]\n",
        "          network[k]['biases'] -= (eta / np.sqrt(v_b[k] + eps)) * db[k]\n",
        "    \n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "\n",
        "  return batch_loss_values, train_stats, valid_stats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OhU1Zf9owIh"
      },
      "source": [
        "def adam_gradient_descent(X, Y, network, batch_size = 1, eta = 5e-2, max_epochs = 50, loss_fn = CrossEntropy_loss, eps = 1e-8, beta1 = 0.9, \n",
        "                          beta2 = 0.999, weight_decay=0, regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, \n",
        "                          validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using Adam Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      eps -- Epsilon hyperparameter\n",
        "      beta1 -- Hyperparameter acting as decaying weight for momentum update\n",
        "      beta2 -- Hyperparameter acting as decaying weight for learning rate update\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "  \n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "  dw, db, v_w, v_b, m_w, m_b, = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                                [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                                [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "  \n",
        "  for epoch in tqdm(range(max_epochs)):  \n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "        batch += 1\n",
        "        Y_true = Y[:,i:i+batch_size]\n",
        "        Y_pred = forward_propagation(network, X[:,i:i+batch_size])\n",
        "        batch_curr_loss = overall_loss(network, Y_pred, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "        dw, db = back_propagation(network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "        batch_loss_values.append(batch_curr_loss)\n",
        "        wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "        for k in range(L):\n",
        "          m_w[k] = m_w[k] * beta1 + (1-beta1) * dw[k]\n",
        "          m_b[k] = m_b[k] * beta1 + (1-beta1) * db[k]\n",
        "          v_w[k] = v_w[k] * beta2 + (1-beta2) * dw[k]**2\n",
        "          v_b[k] = v_b[k] * beta2 + (1-beta2) * db[k]**2\n",
        "          m_w_hat = m_w[k] / (1 - math.pow(beta1, batch))\n",
        "          m_b_hat = m_b[k] / (1 - math.pow(beta1, batch))\n",
        "          v_w_hat = v_w[k] / (1 - math.pow(beta2, batch))\n",
        "          v_b_hat = v_b[k] / (1 - math.pow(beta2, batch))\n",
        "          network[k]['weights'] -= (eta / np.sqrt(v_w_hat + eps)) * m_w_hat\n",
        "          network[k]['biases'] -= (eta / np.sqrt(v_b_hat + eps)) * m_b_hat\n",
        "\n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "  \n",
        "  return batch_loss_values, train_stats, valid_stats\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9lk1FkKdZj1"
      },
      "source": [
        "# Nadam optimisation followed from this paper : https://arxiv.org/pdf/1609.04747.pdf\n",
        "def nadam_gradient_descent(X, Y, network, batch_size = 1, eta = 5e-2, max_epochs = 100, loss_fn = CrossEntropy_loss, eps = 1e-8, beta1 = 0.9, \n",
        "                           beta2 = 0.999, weight_decay=0, regularisation_fn = L2_regularisation, grad_reglr_fn = grad_L2_regularisation, \n",
        "                           validX = None, validY = None):\n",
        "  \"\"\"\n",
        "    Trains the neural network using Nadam Accelerated Gradient Descent\n",
        "    \n",
        "    Arguments :\n",
        "      X -- Input data matrix where ith column is the input data corresponding to ith training example\n",
        "      Y -- True output matrix where ith column is the output data corresponding to ith training example\n",
        "      network -- Given neural network (as an array of dictionaries)\n",
        "      eta -- Learning Rate\n",
        "      max_epochs -- Number of iterations for convergence\n",
        "      loss_fn -- Function used to calculate the loss in the neural network\n",
        "      eps -- Epsilon hyperparameter\n",
        "      beta1 -- Hyperparameter acting as decaying weight for momentum update\n",
        "      beta2 -- Hyperparameter acting as decaying weight for learning rate update\n",
        "      weight_decay -- Hyperparameter scaling regularisation term\n",
        "      regularisation_fn -- (wat the name suggests)\n",
        "      grad_reglr_fn -- Function calculating gradient of the regularisation function\n",
        "      validX -- Validation input data (in same format as training data)\n",
        "      validY -- Validation output data (in same format as training data)\n",
        "      \n",
        "    Returns :\n",
        "      batch_loss_values -- List of average loss values after every batch of training\n",
        "      train_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "      valid_stats -- List of tuple (accuracy, average loss) of entire dataset after every epoch of training\n",
        "  \"\"\"\n",
        "  assert(X.shape[1] == Y.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "\n",
        "  batch_loss_values, train_stats, valid_stats = [], [], []\n",
        "  L = len(network)\n",
        "  batch_curr_loss, batch = 0, 0\n",
        "  dw, db, m_w, m_b, v_w, v_b = [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                               [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)], \\\n",
        "                               [np.zeros_like(network[k]['weights']) for k in range(L)], [np.zeros_like(network[k]['biases']) for k in range(L)]\n",
        "\n",
        "\n",
        "  for epoch in tqdm(range(max_epochs)):  \n",
        "    for i in range(0, X.shape[1], batch_size):\n",
        "      batch += 1\n",
        "      Y_true = Y[:,i:i+batch_size]\n",
        "      Y_pred = forward_propagation(network, X[:,i:i+batch_size])\n",
        "      batch_curr_loss = overall_loss(network, Y_pred, Y_true, loss_fn, weight_decay, regularisation_fn)\n",
        "      dw, db = back_propagation(network, Y_true, Y_pred, weight_decay, grad_reglr_fn)\n",
        "      batch_loss_values.append(batch_curr_loss)\n",
        "      wandb.log({'batch': batch, 'epoch': epoch, 'batch_loss': batch_curr_loss})\n",
        "      for k in range(L):\n",
        "        m_w[k] = m_w[k] * beta1 + (1-beta1) * dw[k]\n",
        "        m_b[k] = m_b[k] * beta1 + (1-beta1) * db[k]\n",
        "        v_w[k] = v_w[k] * beta2 + (1-beta2) * dw[k]**2\n",
        "        v_b[k] = v_b[k] * beta2 + (1-beta2) * db[k]**2\n",
        "        m_w_hat = m_w[k] / (1 - math.pow(beta1, batch))\n",
        "        m_b_hat = m_b[k] / (1 - math.pow(beta1, batch))\n",
        "        v_w_hat = v_w[k] / (1 - math.pow(beta2, batch))\n",
        "        v_b_hat = v_b[k] / (1 - math.pow(beta2, batch))\n",
        "        network[k]['weights'] -= (eta / np.sqrt(v_w_hat + eps)) * (m_w_hat + (1-beta1) / (1 - math.pow(beta1, batch)) * dw[k])\n",
        "        network[k]['biases'] -= (eta / np.sqrt(v_b_hat + eps)) * (m_b_hat + (1-beta1) / (1 - math.pow(beta1, batch)) * db[k])\n",
        "\n",
        "    train_stats.append(calc_accuracy_loss(network, X, Y, loss_fn, weight_decay, regularisation_fn))\n",
        "    if validX is not None:\n",
        "      valid_stats.append(calc_accuracy_loss(network, validX, validY, loss_fn, weight_decay, regularisation_fn))\n",
        "    \n",
        "    wandb.log({'epoch': epoch, 'validation_accuracy': valid_stats[-1][0] if validX is not None else 0, 'accuracy': train_stats[-1][0], \n",
        "              'validation_loss': valid_stats[-1][1] if validX is not None else 0, 'loss': train_stats[-1][1]})\n",
        "  \n",
        "  return batch_loss_values, train_stats, valid_stats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOmXZeotoxbV"
      },
      "source": [
        "def convert_to_onehot(Y, N) :\n",
        "  # Converting output data Y to onehot representation\n",
        "  Y_onehot = []\n",
        "  for y in Y:\n",
        "    curr_y = [0] * N\n",
        "    curr_y[y] = 1\n",
        "    Y_onehot.append(curr_y)\n",
        "\n",
        "  return np.array(Y_onehot).T\n",
        "\n",
        "def train_validation_split(X, Y, train_to_valid_ratio = 0.9):\n",
        "  # Function to split the given input and output data into training and validation sets in the ratio given by train_to_valid_ratio\n",
        "  assert(train_to_valid_ratio > 0 and train_to_valid_ratio < 1)\n",
        "\n",
        "  perm = np.random.permutation(trainX.shape[0])\n",
        "  train_size = int(train_to_valid_ratio * len(perm))\n",
        "  train_indices = perm[:train_size]\n",
        "  valid_indices = perm[train_size:]\n",
        "\n",
        "  return X[train_indices], Y[train_indices], X[valid_indices], Y[valid_indices]\n",
        "\n",
        "def transform_NN_IO(X, Y, no_output_class):\n",
        "  # Function to transform the input and output to a form compatible with the Neural Network functions\n",
        "  X_norm = X.reshape(X.shape[0], (X.shape[1]*X.shape[2])).T / 255   # Input Training data with ith column being ith training example's data\n",
        "  Y_onehot = convert_to_onehot(Y, no_output_class)                  # Converting y labels to onehot representation\n",
        "\n",
        "  return X_norm, Y_onehot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy7GHtEA3Kwv"
      },
      "source": [
        "# Encoding the functions with strings for using in sweep\n",
        "get_grad = {\n",
        "    'sigmoid' : grad_sigmoid,\n",
        "    'tanh' : grad_tanh,\n",
        "    'relu' : grad_relu\n",
        "}\n",
        "\n",
        "get_gd_function = {\n",
        "    'sgd' : sgd_gradient_descent, \n",
        "    'momentum' : momentum_gradient_descent, \n",
        "    'nesterov' : nesterov_gradient_descent, \n",
        "    'rmsprop' : rmsprop_gradient_descent, \n",
        "    'adam' : adam_gradient_descent, \n",
        "    'nadam' : nadam_gradient_descent \n",
        "}\n",
        "\n",
        "get_activ_fn = {\n",
        "    'sigmoid' : sigmoid,\n",
        "    'tanh' : tanh,\n",
        "    'relu' : relu\n",
        "}\n",
        "\n",
        "get_weight_init_fn = {\n",
        "    'random': random_initialisation, \n",
        "    'xavier': xavier_initialisation\n",
        "}\n",
        "\n",
        "get_regularisation_fn = {\n",
        "    'L2': L2_regularisation,\n",
        "    'L1': L1_regularisation\n",
        "}\n",
        "\n",
        "get_grad_reglr_fn = {\n",
        "    'L2': grad_L2_regularisation,\n",
        "    'L1': grad_L1_regularisation\n",
        "}\n",
        "\n",
        "\n",
        "def train_NN(trainX, trainY, optimisation_fn, batch_size, learning_rate, max_epochs, no_hidden_layers, size_hidden_layer, weight_initialisation_fn,\n",
        "             activation_fn, pre_activation_fn = linear, output_fn = softmax, grad_act_fn = grad_sigmoid, \n",
        "             grad_output_fn = Softmax_CrossEntropy_grad, loss_fn = CrossEntropy_loss, weight_decay = 0, regularisation_fn = L2_regularisation,\n",
        "             grad_reglr_fn = grad_L2_regularisation, validX = None, validY = None, testX = None, testY = None):\n",
        "  \n",
        "  # Setting the hyperparameters in the wandb\n",
        "  wandb.config.update({\"no_hidden_layers\": no_hidden_layers, \n",
        "                       \"size_hidden_layer\": size_hidden_layer,\n",
        "                       \"batch_size\": batch_size,\n",
        "                       \"learning_rate\": learning_rate,\n",
        "                       \"no_epochs\": max_epochs,\n",
        "                      })\n",
        "  \n",
        "  assert(trainX.shape[1] == trainY.shape[1])\n",
        "  if validY is not None:\n",
        "    assert(validX.shape[1] == validY.shape[1])\n",
        "  if testY is not None:\n",
        "    assert(testX.shape[1] == testY.shape[1])\n",
        "    \n",
        "  L = no_hidden_layers+1                                # Number of hidden layerws + Output layer in the neural network\n",
        "  n_L = [size_hidden_layer] * (L+1)                     # List of number of neurons in the neural network\n",
        "\n",
        "  n_L[0] = trainX.shape[0]\n",
        "  n_L[L] = trainY.shape[0]\n",
        "\n",
        "  pre_act_fns_L = [pre_activation_fn] * L               # List of Pre-activation functions of the hidden layers and output layer\n",
        "  act_fns_L = [activation_fn] * (L-1) + [output_fn]     # List of Activation functions of the hidden layers and output layer\n",
        "  grad_act_fns_L = [grad_act_fn] * (L-1)                # List of Gradients of the Activation functions, of the hidden layers\n",
        "\n",
        "  network = initialize_network(n_L, pre_act_fns_L, act_fns_L, grad_act_fns_L, grad_output_fn, weight_initialisation_fn)\n",
        "  batch_loss_values, train_stats, valid_stats = optimisation_fn(trainX, trainY, network, batch_size, learning_rate, max_epochs, \n",
        "                                                                loss_fn, weight_decay = weight_decay, regularisation_fn = regularisation_fn, \n",
        "                                                                grad_reglr_fn = grad_reglr_fn, validX = validX, validY = validY)\n",
        "  if testY is not None: \n",
        "    test_stats = calc_accuracy_loss(network, testX, testY, loss_fn, weight_decay, regularisation_fn)\n",
        "    wandb.log({'test_accuracy': test_stats[0], 'test_loss': test_stats[1]})\n",
        "    print(test_stats)\n",
        "\n",
        "  plt.plot(batch_loss_values)\n",
        "  plt.show()\n",
        "  # plt.plot(train_stats[:][0])\n",
        "  # plt.show()\n",
        "  # plt.plot(train_stats[:][1])\n",
        "  # plt.show()\n",
        "\n",
        "  return network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dd13f569360b419a8b5e646c2efaff6f",
            "ad14abf4b0094727b4f80b1d3e525c03",
            "d347893b01f94b01924ba44b21f37ff2",
            "848b38c08e194923a05a7ef9f05ce7f9",
            "0b81e30c4c364e63aa8b4d28a904607f",
            "4ca3adb1a208443abc78fce17f85896e",
            "ce19490681f34ce1a6cb4fef3d1c56db",
            "106676763303483a8e5c705abb61cd08",
            "6b5ab8fe81c248b0b9e3b5df324f3d75",
            "d095224745734cf6afc33586ca6238f9",
            "1378e4fd092f48d585e52c945d71cca4",
            "d16f16ff8359445889d2f0c45ed1e385",
            "c07bb1a8480a40f3b695fa3d87a9d606",
            "5aa85d8732094e4fb3dff6a757e8490d",
            "520b895e0c4b4304bad644188722c90f",
            "851c6db52e5544caa15446e3f83ca045"
          ]
        },
        "id": "OKQ4md7QrEuy",
        "outputId": "5da0087f-c4f1-4697-d8cc-ca7e0ca48015"
      },
      "source": [
        "trainX_split, trainY_split, validX_split, validY_split = train_validation_split(trainX, trainy, 0.9)\n",
        "trainX_tr, trainY_tr = transform_NN_IO(trainX_split, trainY_split, N_CLASSES)\n",
        "validX_tr, validY_tr = transform_NN_IO(validX_split, validY_split, N_CLASSES)\n",
        "testX_tr, testY_tr = transform_NN_IO(testX, testy, N_CLASSES)\n",
        "\n",
        "# Questions 2,3\n",
        "# run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "# network = train_NN(trainX_tr, trainY_tr, sgd_gradient_descent, 16, 1e-2, 10, 2, 10, random_initialisation, tanh, linear, softmax, grad_tanh,\n",
        "#                    grad_output_fn = Softmax_SquaredError_grad, loss_fn = SquaredError,\n",
        "#                    weight_decay = 0.0005, validX = validX_tr, validY = validY_tr, testX = testX_tr, testY = testY_tr)\n",
        "# run.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:1m71m5ex) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 123<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd13f569360b419a8b5e646c2efaff6f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210311_102843-1m71m5ex/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210311_102843-1m71m5ex/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">daily-sun-1008</strong>: <a href=\"https://wandb.ai/abisheks/assignment1/runs/1m71m5ex\" target=\"_blank\">https://wandb.ai/abisheks/assignment1/runs/1m71m5ex</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:1m71m5ex). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.22<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">pious-sun-1009</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment1\" target=\"_blank\">https://wandb.ai/abisheks/assignment1</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/abisheks/assignment1/runs/2f7haacu\" target=\"_blank\">https://wandb.ai/abisheks/assignment1/runs/2f7haacu</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210311_102942-2f7haacu</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:32<00:00,  3.28s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(0.7964, 0.20125937010194261)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 163<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b5ab8fe81c248b0b9e3b5df324f3d75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210311_102942-2f7haacu/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210311_102942-2f7haacu/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>batch</td><td>33750</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>batch_loss</td><td>0.10964</td></tr><tr><td>_runtime</td><td>35</td></tr><tr><td>_timestamp</td><td>1615458620</td></tr><tr><td>_step</td><td>33760</td></tr><tr><td>validation_accuracy</td><td>0.80033</td></tr><tr><td>accuracy</td><td>0.80978</td></tr><tr><td>validation_loss</td><td>0.20101</td></tr><tr><td>loss</td><td>0.19523</td></tr><tr><td>test_accuracy</td><td>0.7964</td></tr><tr><td>test_loss</td><td>0.20126</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>batch_loss</td><td>███████▇▇▇▇▆▆▆▆▆▆▄▄▄▃▆▄▃▄▄▄▃▃▃▂▃▄▂▃▃▁▂▃▂</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>validation_accuracy</td><td>▁▁▃▅▆▇▇▇██</td></tr><tr><td>accuracy</td><td>▁▁▃▅▆▇▇▇██</td></tr><tr><td>validation_loss</td><td>█▇▆▅▃▃▂▂▁▁</td></tr><tr><td>loss</td><td>█▇▆▅▃▃▂▂▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">pious-sun-1009</strong>: <a href=\"https://wandb.ai/abisheks/assignment1/runs/2f7haacu\" target=\"_blank\">https://wandb.ai/abisheks/assignment1/runs/2f7haacu</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT5lxNGplX5L"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',                   # Possible search : grid, random, bayes\n",
        "    'metric': {\n",
        "      'name': 'validation_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'no_epochs': {\n",
        "            'values': [5, 10]\n",
        "        },\n",
        "        'no_hidden_layers': {\n",
        "            'values': [3, 4, 5]\n",
        "        },\n",
        "        'size_hidden_layer': {\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'weight_decay' :{\n",
        "            'values': [0, 0.005, 0.0005]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-1, 1e-2, 1e-3]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['sgd', 'momentum', 'nesterov', 'rmsprop', 'adam', 'nadam' ]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [16, 32, 64]\n",
        "        },\n",
        "        'weight_initialisation': {\n",
        "            'values': ['random', 'xavier']\n",
        "        },\n",
        "        'activation_fn': {\n",
        "            'values': ['relu', 'tanh', 'sigmoid']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# sweep_id = wandb.sweep(sweep_config, entity=\"abisheks\", project=\"assignment1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLYFa9Jh7rU0"
      },
      "source": [
        "def sweep_wrapper():\n",
        "  # Default values for hyper-parameters we're going to sweep over\n",
        "  config_defaults =  {\n",
        "      'no_epochs': 5,\n",
        "      'no_hidden_layers': 3,\n",
        "      'size_hidden_layer': 32, \n",
        "      'weight_decay' : 0,\n",
        "      'learning_rate': 1e-2,\n",
        "      'optimizer': 'adam',\n",
        "      'batch_size': 128,\n",
        "      'weight_initialisation': 'random', \n",
        "      'activation_fn': 'relu'\n",
        "  }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  run = wandb.init(config=config_defaults, reinit=True)\n",
        "  \n",
        "  # Config is a variable that holds and saves hyperparameters and inputs\n",
        "  config = wandb.config\n",
        "  wandb.config.update({'no_classes': N_CLASSES})\n",
        "\n",
        "  wandb.run.name = f'hl_{config.no_hidden_layers}_bs_{config.batch_size}_ac_{config.activation_fn}'\n",
        "  wandb.run.save()\n",
        "\n",
        "  train_NN(trainX_tr, trainY_tr, get_gd_function[config.optimizer], config.batch_size, config.learning_rate, \n",
        "           config.no_epochs, config.no_hidden_layers, config.size_hidden_layer, get_weight_init_fn[config.weight_initialisation],\n",
        "           get_activ_fn[config.activation_fn], linear, softmax, get_grad[config.activation_fn], \n",
        "           Softmax_SquaredError_grad, SquaredError, config.weight_decay, L2_regularisation, grad_L2_regularisation, \n",
        "           validX_tr, validY_tr, testX_tr, testY_tr)\n",
        "  \n",
        "  run.finish()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTMh4OI7HGzC"
      },
      "source": [
        "# Questions 4-6\n",
        "# wandb.agent('abisheks/assignment1/9ks8kwx5', sweep_wrapper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHHZemXkdwVb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3bbcaa033cae47c5b05246c8686dbc2d",
            "0bd78c33fcc74b18befd665a9127e667",
            "bc00c5e74a9244debba5d062c1a03f77",
            "82af286ddd4247c7807f5918e13c52bd",
            "e8664d3e75104daf9059aa36a663e55c",
            "cc379116e12e4024bd024a912f419f42",
            "0cc17d15c654474ba33216f4c7101d85",
            "ab7a466bda8144c39ce96331ddc1fbe3"
          ]
        },
        "outputId": "383407df-a620-49cd-b04d-f63d9ff23d72"
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(network, X, Y):\n",
        "  # Function to plot the confusion matrix for a given trained network, input (X) and true output (Y)\n",
        "  Y_pred = forward_propagation(network, X)\n",
        "  cm = confusion_matrix(np.argmax(Y, axis=0), np.argmax(Y_pred, axis=0))\n",
        "\n",
        "  df_cm = pd.DataFrame(cm, [IMG_LABELS[i] for i in range(cm.shape[0])], [IMG_LABELS[i] for i in range(cm.shape[0])])\n",
        "  plt.figure(figsize=(20,20))\n",
        "  sn.set(font_scale=1.0) # for label size\n",
        "  sn.heatmap(df_cm, annot=True, \n",
        "            annot_kws={\"size\": 16}, cmap='flare', fmt='g'\n",
        "            ) # font size\n",
        "  # plt.show()\n",
        "  wandb.log({'Confusion Matrix': plt})\n",
        "\n",
        "# Question 7\n",
        "run = wandb.init(project=\"assignment1\", entity=\"abisheks\", reinit=True)\n",
        "network = train_NN(trainX_tr, trainY_tr, momentum_gradient_descent, 64, 1e-2, 10, 4, 128, xavier_initialisation, relu, linear, softmax, grad_relu,\n",
        "                   grad_output_fn = Softmax_CrossEntropy_grad, loss_fn = CrossEntropy_loss,\n",
        "                   weight_decay = 0.0005, validX = validX_tr, validY = validY_tr, testX = testX_tr, testY = testY_tr)\n",
        "\n",
        "plot_confusion_matrix(network, testX_tr, testY_tr)\n",
        "run.finish()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2vvc95jw) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 1458, in _atexit_cleanup\n",
            "    self._on_finish()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 1594, in _on_finish\n",
            "    self.history._flush()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_history.py\", line 59, in _flush\n",
            "    self._callback(row=self._data, step=self._step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 790, in _history_callback\n",
            "    row, step, publish_step=not_using_tensorboard\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\", line 212, in publish_history\n",
            "    data = data_types.history_dict_to_json(run, data, step=step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/data_types.py\", line 1995, in history_dict_to_json\n",
            "    payload[key] = val_to_json(run, key, val, namespace=step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/data_types.py\", line 2023, in val_to_json\n",
            "    val = Plotly.make_plot_media(val)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/data_types.py\", line 1945, in make_plot_media\n",
            "    val = util.matplotlib_to_plotly(val)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/util.py\", line 414, in matplotlib_to_plotly\n",
            "    return tools.mpl_to_plotly(obj)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/plotly/tools.py\", line 112, in mpl_to_plotly\n",
            "    matplotlylib.Exporter(renderer).run(fig)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/plotly/matplotlylib/mplexporter/exporter.py\", line 51, in run\n",
            "    self.crawl_fig(fig)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/plotly/matplotlylib/mplexporter/exporter.py\", line 116, in crawl_fig\n",
            "    props=utils.get_figure_properties(fig)):\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 112, in __enter__\n",
            "    return next(self.gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/plotly/matplotlylib/mplexporter/renderers/base.py\", line 45, in draw_figure\n",
            "    self.open_figure(fig=fig, props=props)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/plotly/matplotlylib/renderer.py\", line 90, in open_figure\n",
            "    self.mpl_x_bounds, self.mpl_y_bounds = mpltools.get_axes_bounds(fig)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/plotly/matplotlylib/mpltools.py\", line 265, in get_axes_bounds\n",
            "    x_min, y_min, x_max, y_max = min(x_min), min(y_min), max(x_max), max(y_max)\n",
            "ValueError: min() arg is an empty sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2vvc95jw). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.22<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">dry-bird-1021</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment1\" target=\"_blank\">https://wandb.ai/abisheks/assignment1</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/abisheks/assignment1/runs/32hr3zys\" target=\"_blank\">https://wandb.ai/abisheks/assignment1/runs/32hr3zys</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210311_105625-32hr3zys</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:03<00:00,  6.36s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(0.8664, 0.508516715371562)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/plotly/matplotlylib/renderer.py:474: UserWarning:\n",
            "\n",
            "Dang! That path collection is out of this world. I totally don't know what to do with it yet! Plotly can only import path collections linked to 'data' coordinates\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 496<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bbcaa033cae47c5b05246c8686dbc2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.03MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.01820762123…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210311_105625-32hr3zys/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210311_105625-32hr3zys/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>batch</td><td>8440</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>batch_loss</td><td>0.33399</td></tr><tr><td>_runtime</td><td>67</td></tr><tr><td>_timestamp</td><td>1615460254</td></tr><tr><td>_step</td><td>8451</td></tr><tr><td>validation_accuracy</td><td>0.86567</td></tr><tr><td>accuracy</td><td>0.8953</td></tr><tr><td>validation_loss</td><td>0.51262</td></tr><tr><td>loss</td><td>0.42632</td></tr><tr><td>test_accuracy</td><td>0.8664</td></tr><tr><td>test_loss</td><td>0.50852</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>batch_loss</td><td>█▇▆▇▆▄▆▄▄▅▄▄▃▃▃▃▂▃▄▂▅▅▃▁▄▂▄▃▂▃▂▂▁▄▂▃▂▁▂▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>validation_accuracy</td><td>▁▃▄▅▅▆▆▇██</td></tr><tr><td>accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>validation_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">dry-bird-1021</strong>: <a href=\"https://wandb.ai/abisheks/assignment1/runs/32hr3zys\" target=\"_blank\">https://wandb.ai/abisheks/assignment1/runs/32hr3zys</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}